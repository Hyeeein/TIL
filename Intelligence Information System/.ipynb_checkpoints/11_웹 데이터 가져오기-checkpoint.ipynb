{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8e3842",
   "metadata": {},
   "source": [
    "## 웹 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d591b",
   "metadata": {},
   "source": [
    "### 필요한 라이브러리\n",
    "\n",
    "- urllib\n",
    "- BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec6752",
   "metadata": {},
   "source": [
    "### 1. urllib\n",
    "\n",
    "* 인터넷에서 데이터를 받아 오는 기능들이 들어 있는 파이썬 패키지\n",
    "\n",
    "\n",
    "* urllib에 인터넷 주소(URL)을 넣고 실행하면, 데이터를 텍스트 형태로 받아옴\n",
    "    - 크롤링? 데이터를 받아오는 것\n",
    "    - 즉, urllib는 크롤링을 하는 라이브러리\n",
    "    \n",
    "    \n",
    "* urllib은 기본적으로 내장되어 있으므로, 파이썬이 설치되어 있다면 바로 import 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fe3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c7780",
   "metadata": {},
   "source": [
    "### 2. BeautifulSoup\n",
    "\n",
    "\n",
    "* 데이터를 추출하는 데 필요한 기능이 들어 있는 라이브러리\n",
    "    - 파싱(parsing) 라이브러리라고도 함\n",
    "    \n",
    "    \n",
    "* 데이터를 받아오는 건 '크롤링'이고, 받아온 데이터에서 필요한 내용만 추출하는 것을 '파싱'이라고 함\n",
    "\n",
    "\n",
    "* 외부 라이브러리이기 때문에 따로 설치해주어야 함\n",
    "    - 우리는 따로 설치할 필요 없음. Anaconda 설치할 때 설치했기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffaacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db053da6",
   "metadata": {},
   "source": [
    "### BeautifulSoup 사용 예\n",
    "\n",
    "\n",
    "* BeautifulSoup() 사용하기\n",
    "\n",
    "    - BeautifulSoup(<받은 텍스트>, <텍스트를 파싱할 파서>)와 같은 형태로 사용\n",
    "    \n",
    "    - 웹 문서 대부분은 HTML로 되어 있음. html.parser (가장 많이 사용)\n",
    "    - 이 외에 lxml, xml 등 다른 파서도 존재\n",
    "    \n",
    "    \n",
    "* soup = BeautifulSoup(html_str, \"html.parser\")를 이용하여 html 데이터(변수명; html_str) 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e111dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<html><div>hello</div></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_str = \"<html><div>hello</div></html>\"\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "print(type(soup))\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b771d55",
   "metadata": {},
   "source": [
    "### 3. find()\n",
    "\n",
    "* find()를 이용하여 파싱된 데이터 중 필요한 부분만 뽑아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc150167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<html><div>hello</div></html>\n",
      "<div>hello</div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_str = \"<html><div>hello</div></html>\"\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "print(type(soup))\n",
    "print(soup)\n",
    "print(soup.find(\"div\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377cb232",
   "metadata": {},
   "source": [
    "#### (1) `<div>` 태그\n",
    "\n",
    "\n",
    "* Division의 약자\n",
    "\n",
    "\n",
    "* 웹 페이지의 영역을 구분하기 위해 사용되며, 전체적인 틀(레이아웃)을 잡을 때 사용\n",
    "    - Table 태그 이용 -> div 태그와 span 태그 이용\n",
    "\n",
    "\n",
    "* 마크업 언어는 HTML의 각 줄마다 의미를 부여하기 위해 존재하지만, `<div>` 태그는 의미가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c75ac7",
   "metadata": {},
   "source": [
    "#### (2) `<ul>` 태그\n",
    "\n",
    "\n",
    "* 순서 없는 목록(Unordered List) 만들기\n",
    "\n",
    "\n",
    "* 일반적으로, `<li>` 태그와 같이 사용됨\n",
    "    - `<ul>` 태그 안에 `<li>` 태그를 이용\n",
    "    - 각 항목에 작은 원이나 사각형 같은 불렛이 생김 (Default 값이 작은 원)\n",
    "\n",
    "\n",
    "* 'div' 대신 'ul'을 사용하여 작성하는 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e13e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n",
      "<li>line1</li>\n",
      "<li>line2</li>\n",
      "<li>line3</li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 여러 줄의 문자열을 사용하기 위해 문자열의 시작 줄과 끝 줄에 각각 \"\"\", \"\"\" 사용\n",
    "\n",
    "html_str = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <ul>\n",
    "            <li>line1</li>\n",
    "            <li>line2</li>\n",
    "            <li>line3</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "ul = soup.find(\"ul\")\n",
    "li = ul.find(\"li\")\n",
    "print(ul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7a6a0",
   "metadata": {},
   "source": [
    "#### (3) `<ol>` 태그\n",
    "\n",
    "\n",
    "* 순서 있는 목록 (Ordered List) 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6337aa",
   "metadata": {},
   "source": [
    "#### (4) 텍스트만 추출하기\n",
    "\n",
    "* `<li>`, `</li>` 태그 안에 있는 'line1'만 뽑으려면? .text 속성을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc7abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line1\n"
     ]
    }
   ],
   "source": [
    "print(li.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3ff93",
   "metadata": {},
   "source": [
    "### 4. find_all()\n",
    "\n",
    "* 조건에 해당하는 모든 요소를 **리스트 [] 형태**로 추출해주는 기능\n",
    "    - find(): 조건을 만족하는 첫 번째 태그를 리턴\n",
    "\n",
    "\n",
    "* 만약 line1이 아니라, line3을 가져오고 싶다면?\n",
    "    - 인덱스로 리스트 데이터에 접근\n",
    "    - 태그 안에 있는 텍스트만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d92fac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n",
      "<li>line1</li>\n",
      "<li>line2</li>\n",
      "<li>line3</li>\n",
      "</ul>\n",
      "[<li>line1</li>, <li>line2</li>, <li>line3</li>]\n",
      "<li>line3</li>\n",
      "line3\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 여러 줄의 문자열을 사용하기 위해 문자열의 시작 줄과 끝 줄에 각각 \"\"\", \"\"\" 사용\n",
    "\n",
    "html_str = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <ul>\n",
    "            <li>line1</li>\n",
    "            <li>line2</li>\n",
    "            <li>line3</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "ul = soup.find(\"ul\")\n",
    "li = ul.find(\"li\")\n",
    "print(ul)\n",
    "\n",
    "lis = ul.find_all(\"li\")\n",
    "print(lis)\n",
    "print(lis[2])\n",
    "print(lis[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c9cdc",
   "metadata": {},
   "source": [
    "* 버전에 따른 차이\n",
    "\n",
    "    - BeautifulSoup3 버전 : findAll() 사용\n",
    "    - BeautifulSoup4 버전 : find_all() 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f934398",
   "metadata": {},
   "source": [
    "### 5. class 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67731eb6",
   "metadata": {},
   "source": [
    "#### (1) 태그와 속성 그리고 속성값\n",
    "\n",
    "\n",
    "* HTML\n",
    "    - `<html>`로 시작해서 `</html>`로 끝나는 문서\n",
    "    - 태그(tag)와 속성(property)로 이루어져 있음\n",
    "    \n",
    "    \n",
    "* **태그(tag)**\n",
    "    - `<ul> </ul>`, `<li> </li>`, `<div> </div>`, `<a> </a>` 처럼 <>로 감싸져 있는 것이며, `<ul>`로 시작했으면 `</ul>`로 끝나야 함\n",
    "    \n",
    "    \n",
    "* 속성(Property)과 속성값?\n",
    "    - `<ul class=\"class1\">`: ul 태그, class 속성, \"class1\" 속성값\n",
    "    - `<a href = \"https://www.google.com/\">구글</a>`: a 태그, href 속성, \"https://www.google.com\" 속성값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569c34d",
   "metadata": {},
   "source": [
    "#### (2) class 속성 이용하기\n",
    "\n",
    "\n",
    "* 데이터를 뽑을 때, class 속성 이용하기\n",
    "    - ul = soup.find(\"ul\")\n",
    "    \n",
    "    \n",
    "* 조건을 추가하여 우리가 뽑고 싶은 요소에 조금 더 정확하게 접근하기\n",
    "    - ul = soup.find(\"ul\", {\"class\":\"class2\"})\n",
    "\n",
    "\n",
    "* class와 id의 차이?\n",
    "    - id는 웹 페이지에서 유일해야 함\n",
    "    - class는 여러 번 사용 가능\n",
    "    - 그래서, 보통 class는 일반적인 이름으로 짓고, 아이디는 특수하게 지음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4858e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"class2\">\n",
      "<li>line4</li>\n",
      "<li>line5</li>\n",
      "<li>line6</li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 여러 줄의 문자열을 사용하기 위해 문자열의 시작 줄과 끝 줄에 각각 \"\"\", \"\"\" 사용\n",
    "\n",
    "html_str = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <ul class=\"class1\">\n",
    "            <li>line1</li>\n",
    "            <li>line2</li>\n",
    "            <li>line3</li>\n",
    "        </ul>\n",
    "        <ul class=\"class2\">\n",
    "            <li>line4</li>\n",
    "            <li>line5</li>\n",
    "            <li>line6</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "ul = soup.find(\"ul\", {\"class\":\"class2\"})\n",
    "print(ul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53caccbe",
   "metadata": {},
   "source": [
    "#### (3) 속성값 추출하기\n",
    "\n",
    "* `<a>` 태그 값 뽑아내기\n",
    "    - ul = soup.find(\"a\")\n",
    "    \n",
    "\n",
    "* 링크 추출\n",
    "    - `<a>` 태그의 href 속성의 속성값을 뽑아내어 링크를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ee1a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://www.naver.com\">네이버</a>\n",
      "https://www.naver.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 여러 줄의 문자열을 사용하기 위해 문자열의 시작 줄과 끝 줄에 각각 \"\"\", \"\"\" 사용\n",
    "\n",
    "html_str = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <ul class=\"search\">\n",
    "            <li>\n",
    "                <a href=\"https://www.naver.com\">네이버</a>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"https://www.google.com\">구글</a>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <ul class=\"sns\">\n",
    "            <li>\n",
    "                <a href=\"https://www.facebook.com\">페이스북</a>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"https://www.instagram.com\">인스타그램</a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_str, \"html.parser\")\n",
    "\n",
    "ul = soup.find(\"a\")\n",
    "print(ul)\n",
    "print(ul['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58e3e6",
   "metadata": {},
   "source": [
    "### 6. find()와 select()\n",
    "\n",
    "\n",
    "* find()와 find_all()\n",
    "    - find() : 조건을 만족하는 첫 번째 태그를 리턴\n",
    "    - find_all() : 조건에 해당하는 모든 요소를 리스트로 리턴\n",
    "    \n",
    "\n",
    "* select() 함수를 사용하여 원하는 데이터 추출하기\n",
    "    - css_selector를 활용하여 원하는 태그를 찾는 방법\n",
    "    \n",
    "\n",
    "* BeautifulSoup으로 html 문서를 파싱하는 방법\n",
    "    - find(): html tag를 통한 크롤링\n",
    "    - find_all(): css를 통한 크롤링\n",
    "    - find_all()과 select()는 기능적으로 동일\n",
    "        - 둘 중 선택하여 사용\n",
    "        - But, 두 가지 방법을 함께 사용하는 경우가 더 많음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
