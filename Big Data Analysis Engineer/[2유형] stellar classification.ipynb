{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc7c71f",
   "metadata": {},
   "source": [
    "## 2유형 [4] Stellar-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95029d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력을 원하실 경우 print() 함수 활용\n",
    "# 예시) print(df.head())\n",
    "\n",
    "# getcwd(), chdir() 등 작업 폴더 설정 불필요\n",
    "# 파일 경로 상 내부 드라이브 경로(C: 등) 접근 불가\n",
    "\n",
    "# 데이터 파일 읽기 예제\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "X_test = pd.read_csv(\"./datasets/Part2/stellar_X_test.csv\")\n",
    "X_train = pd.read_csv(\"./datasets/Part2/stellar_X_train.csv\")\n",
    "y_train = pd.read_csv(\"./datasets/Part2/stellar_y_train.csv\")\n",
    "\n",
    "# 사용자 코딩\n",
    "\n",
    "# 1. 데이터 전처리\n",
    "# 1) 데이터 확인 -> 결측치 없고, 모두 수치형\n",
    "# print(X_train.info())\n",
    "\n",
    "# 2) 기술통계량\n",
    "# print(X_train.describe())\n",
    "\n",
    "# 3) 이상치 제거 ★\n",
    "y_train = y_train.loc[X_train.u != -9999]\n",
    "X_train = X_train.loc[X_train.u != -9999]\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(X_train.describe())\n",
    "\n",
    "# 4) redshift 데이터의 분위를 살펴보고, 파생변수 만들어주기\n",
    "# print(X_train['redshift'].quantile([q/100 for q in range(90, 101)]))\n",
    "# 전체의 2%만 3을 넘음\n",
    "\n",
    "# 파생변수 추가\n",
    "X_train['redshift_upper3'] = np.where(X_train['redshift']>3, 1, 0)\n",
    "X_test['redshift_upper3'] = np.where(X_test['redshift']>3, 1, 0)\n",
    "\n",
    "# 컬럼 추가\n",
    "COL_DEL = []\n",
    "COL_NUM = ['alpha', 'delta', 'u', 'g', 'r', 'i', 'z', 'redshift']\n",
    "COL_CAT = ['run_ID', 'rerun_ID', 'cam_col', 'field_ID', 'plate', 'redshift_upper3']\n",
    "COL_Y = ['galaxy']\n",
    "\n",
    "X_train[COL_CAT] = X_train[COL_CAT].astype(str)\n",
    "X_test[COL_CAT] = X_test[COL_CAT].astype(str)\n",
    "\n",
    "X_train = X_train.drop(COL_DEL, axis=1)\n",
    "X_test = X_test.drop(COL_DEL, axis=1)\n",
    "\n",
    "# 5) 수치형 데이터가 유효한지 살펴보기\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# for col in COL_NUM:\n",
    "#     print('-'*80)\n",
    "#     print(col)\n",
    "#     print(train_df.groupby(COL_Y)[col].describe(), end='\\n\\n')\n",
    "# 수치형 중 의미있어 보이는 변수 : redshift\n",
    "\n",
    "# 6) 범주형 데이터가 유효한지 살펴보기\n",
    "# for col in COL_CAT:\n",
    "#     print(train_df.groupby(col, as_index=False)[COL_Y].mean().sort_values(by=COL_Y, ascending=False, end='\\n\\n')\n",
    "# 범주형 중 의미있어 보이는 변수 : cam_col, redshift_upper3\n",
    "\n",
    "# 7) 레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = pd.concat([X_train, X_test])\n",
    "\n",
    "for col in COL_CAT:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[col])\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# 2. 모델 구축\n",
    "# 1) 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train)\n",
    "\n",
    "# 2) 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr[COL_NUM] = scaler.fit_transform(X_tr[COL_NUM])\n",
    "X_val[COL_NUM] = scaler.fit_transform(X_val[COL_NUM])\n",
    "X_test[COL_NUM] = scaler.fit_transform(X_test[COL_NUM])\n",
    "\n",
    "# 3) 분류모델 적용 (레이블 인코딩을 했으므로 랜덤포레스트와 XGBoost)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_tr, y_tr.values.ravel())\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# 3. 모델 평가 (ROC_AUC_Score)\n",
    "# 1) 예측값 계산\n",
    "y_pred_rf = model_rf.predict_proba(X_val)\n",
    "y_pred_xgb = model_xgb.predict_proba(X_val)\n",
    "\n",
    "# 2) 평가 점수\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_rf = roc_auc_score(y_val, y_pred_rf[:, 1])\n",
    "score_xgb = roc_auc_score(y_val, y_pred_xgb[:, 1])\n",
    "\n",
    "# print(score_rf, score_xgb)\n",
    "# 높을수록 좋은 모델 : xgboost\n",
    "\n",
    "# 3) 변수 중요도 확인\n",
    "# print(pd.DataFrame({'feature': X_tr.columns, 'fi_rf': model_rf.feature_importances_, \n",
    "#                     'fi_xgb': model_xgb.feature_importances_}))\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# 4. 제출 파일로 저장\n",
    "pred = model_xgb.predict_proba(X_test)[:, 1]\n",
    "pd.DataFrame({'galaxy':pred}).to_csv('./res/04.csv', index=False)\n",
    "\n",
    "# 답안 제출 참고\n",
    "# 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
    "# pd.DataFrame({'gender': pred}).to_csv('003000000.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigbunki",
   "language": "python",
   "name": "bigbunki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
