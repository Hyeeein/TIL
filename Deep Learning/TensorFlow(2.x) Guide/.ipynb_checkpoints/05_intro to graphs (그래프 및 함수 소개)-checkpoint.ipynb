{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04d20eb",
   "metadata": {},
   "source": [
    "## 그래프란 무엇인가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d80bf",
   "metadata": {},
   "source": [
    "* 그래프 실행은 텐서 계산이 `tf.Graph` 또는 간단히 '그래프'라고도 하는 TensorFlow 그래프로 실행됨을 의미\n",
    "\n",
    "\n",
    "* 그래프: 계산의 단위를 나타내는 `tf.Operation` 객체와 연산 간에 흐르는 데이터의 단위를 나타내는 `tf.Tensor` 객체의 세트를 포함. 데이터 구조는 `tf.Graph` 컨텍스트에서 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34fbb7",
   "metadata": {},
   "source": [
    "## 그래프의 이점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aac060",
   "metadata": {},
   "source": [
    "* 그래프 사용시, 유연성이 크게 향상됨 => 빠르게, 병렬로, 여러 기기에서 실행 시 아주 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8107cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a3ea0",
   "metadata": {},
   "source": [
    "## 그래프 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e4f8b",
   "metadata": {},
   "source": [
    "`tf.function`\n",
    "\n",
    "\n",
    "- 직접 호출 또는 데코레이터를 사용하여 TensorFlow에서 그래프를 만들고 실행\n",
    "\n",
    "\n",
    "- 일반 함수를 입력 받아 Function을 반환 (Python의 경우도 동일한 방식으로 Function을 사용) <br>\n",
    "  But, 안을 들여다보면 다르다 !! **하나의 API 뒤에서 여러 `tf.Graph`를 캡슐화 함**\n",
    "  \n",
    "  \n",
    "- 함수 및 이 함수가 호출하는 다른 모든 함수에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7596d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_regular_function(x, y, b):\n",
    "    x = tf.matmul(x, y)  # matmul : 행렬 곱을 더 간단하게 나타낼 수 있음\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
    "\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
    "\n",
    "# 파이썬에서 사용하는 것처럼 함수 사용\n",
    "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
    "assert(orig_value == tf_function_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd2d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_function(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "# outer_function을 Function으로 만들어 데코레이터로 사용\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "    y = tf.constant([[2.0], [3.0]])\n",
    "    b = tf.constant(4.0)\n",
    "\n",
    "    return inner_function(x, y, b)\n",
    "\n",
    "outer_function(tf.constant([[1.0, 2.0]])).numpy()\n",
    "# constant : 텐서 같은 객체에서 상수 텐서 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f70ec3",
   "metadata": {},
   "source": [
    "### Python 함수를 그래프로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9604534",
   "metadata": {},
   "source": [
    "* TensorFlow를 사용하여 작성하는 모든 함수에는 if-then 절, 루프, break, return, continue 등과 같은 내장된 TF 연산과 Python 논리가 혼합\n",
    "\n",
    "\n",
    "* `tf.function`은 AutoGraph(`tf.autograph`)라는 라이브러리를 사용하여 Python 코드를 그래프 생성 코드로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47355c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1\n",
      "Second branch, with graph: 0\n"
     ]
    }
   ],
   "source": [
    "def simple_relu(x):\n",
    "    if tf.greater(x, 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
    "tf_simple_relu = tf.function(simple_relu)\n",
    "\n",
    "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
    "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3094a",
   "metadata": {},
   "source": [
    "### 다형성: 하나의 Function, 다수의 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bf575",
   "metadata": {},
   "source": [
    "`tf.Graph`\n",
    "\n",
    "\n",
    "- 특정 유형의 입력에 특화되어 있음 (특정 dtype, 동일한 id를 가진 객체)\n",
    "\n",
    "\n",
    "- Function을 호출할 때마다, 새 인수에 특화된 새 `tf.Graph`를 생성\n",
    "    - 유형 사양을 **입력 서명** 또는 **서명**이라고 함\n",
    "    - 하지만, 이 서명으로 이미 호출된 경우 새로운 `tf.Graph`를 생성하지 않음\n",
    "    \n",
    "    \n",
    "- Function은 해당 서명에 대응하는 `tf.Graph`를 ConcreteFunction에 저장\n",
    "\n",
    "\n",
    "- 여러 그래프로 뒷받침된다는 점에서 다형성의 특징을 가짐\n",
    "    - 단일 `tf.Graph`로 나타낼 수 있는 것보다 더 많은 입력 유형을 지원하고 더 우수한 성능을 가질 수 있도록 최적화 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14801265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# @tf.function : tf1.x 스타일로 해당 함수 내의 로직이 동작하므로, 속도가 빨라질 수 있음\n",
    "# But, 값을 바로 계산해 볼 수 없어서 모든 로직에 대한 프로그래밍이 끝난 뒤에 붙이는게 좋음\n",
    "@tf.function\n",
    "def my_relu(x):\n",
    "    return tf.maximum(0., x)\n",
    "\n",
    "print(my_relu(tf.constant(5.5)))\n",
    "print(my_relu([1, -1]))\n",
    "print(my_relu(tf.constant([3., -3.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ad7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 여기서는 새로운 그래프를 생성하지 않음\n",
    "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
    "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57852130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=()\n",
      "  Returns:\n",
      "    float32 Tensor, shape=()\n",
      "\n",
      "my_relu(x=[1, -1])\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "\n",
      "my_relu(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "# ConcreteFunction에 3가지 특징이 있음 -> 타입과 쉐입을 반환\n",
    "print(my_relu.pretty_printed_concrete_signatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863061a",
   "metadata": {},
   "source": [
    "## tf.function 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6bb56",
   "metadata": {},
   "source": [
    "### 그래프 실행 vs. 즉시 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081e5bb",
   "metadata": {},
   "source": [
    "`Function` : 즉시 실행 또는 그래프 실행이 가능 (기본적으로 코드를 그래프로 실행함)\n",
    "\n",
    "`tf.config.run_functions_eagerly(True)`\n",
    "- 그래프 실행이 아닌 즉시 실행하도록 할 수 있음\n",
    "\n",
    "\n",
    "- 코드를 정상적으로 실행하는 대신에 그래프를 생성하고 실행하는 Function의 기능을 해제하는 스위치\n",
    "\n",
    "\n",
    "- 하지만, 코드를 다 실행하고 나면 다시 원상태로 돌려야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3393658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "    sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "    return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9156931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 0 0 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([5 4 1 4 8], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# random.uniform : 랜덤으로 균일분포 난수 생성하는 함수\n",
    "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703aa309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d87950c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 실행 말고, 즉시 실행하도록 바꿈\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa45bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc36fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to set it back when you are done.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b48a45",
   "metadata": {},
   "source": [
    "`Function`은 그래프 및 즉시 실행에서 서로 다르게 동작할 수도 있음\n",
    "- 아래 예시를 보면 get_MSE는 3번 호출되었지만 한 번만 인쇄됨\n",
    "\n",
    "\n",
    "- print문은 Function이 원래 코드를 실행할 때 실행되며, 이 때 \"트레이싱\"이라는 프로세스를 통해 그래프를 생성함\n",
    "\n",
    "\n",
    "- **추적은 TensorFlow 연산을 그래프로 캡쳐하고 print는 그래프로 캡쳐되지 않음** 이 그래프는 세 번의 모든 호출 시 실행되지만 Python 코드를 다시 실행하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ce17c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_MSE(y_true, y_pred):\n",
    "    print(\"Calculating MSE!\")\n",
    "    sq_diff = tf.pow(y_true - y_pred, 2)\n",
    "    return tf.reduce_mean(sq_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05b992ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec3e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 즉시 실행\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71dd6883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MSE!\n",
      "Calculating MSE!\n",
      "Calculating MSE!\n"
     ]
    }
   ],
   "source": [
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)\n",
    "error = get_MSE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847c2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 즉시 실행 해제\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e20fd",
   "metadata": {},
   "source": [
    "cf) 즉시 및 그래프 실행 모두에서 값을 인쇄하려면 `tf.print`를 대신 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7977c4",
   "metadata": {},
   "source": [
    "### 비평가(Non-strict) 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2a338",
   "metadata": {},
   "source": [
    "* 그래프 실행 결과\n",
    "    - 함수의 반환 값\n",
    "    - 다음과 같은 문서화된 잘 알려진 부작용:\n",
    "        - `tf.print`와 같은 입/출력 작업\n",
    "        - `tf.debugging`의 어설션 기능과 같은 디버깅 작업\n",
    "        - `tf.Variable`의 변형\n",
    "    - 이 동작은 일반적으로 '비평가 실행'으로 알려져 있음 (즉시 실행과 구분됨)\n",
    "    \n",
    "    \n",
    "* 그래프 실행\n",
    "    - 필요하거나 필요하지 않은 모든 프로그램 작업을 단계별로 실행\n",
    "    - 런타임 오류 검사는 관찰 가능한 효과로 간주되지 않음.\n",
    "    - 아래의 예제에서 불필요한 작업인 `tf.gather`를 건너뛰므로, 런타임 오류 (InvalidArgumentError) 발생 안함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7aedc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvalidArgumentError: {{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 1 is not in [0, 1) [Op:GatherV2]\n"
     ]
    }
   ],
   "source": [
    "def unused_return_eager(x):\n",
    "    # Get index 1 will fail when `len(x) == 1`\n",
    "    tf.gather(x, [1]) # unused \n",
    "    return x\n",
    "\n",
    "try:\n",
    "    print(unused_return_eager(tf.constant([0.0])))\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    # 즉시 실행이 동작하는 동안 모든 오퍼레이션이 실행되므로, 에러가 올라감\n",
    "    print(f'{type(e).__name__}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f3b4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def unused_return_graph(x):\n",
    "    tf.gather(x, [1]) # unused\n",
    "    return x\n",
    "\n",
    "# 그래프 실행하는 동안 오직 필요한 오퍼레이션만 실행. 에러는 올라가지 않음\n",
    "print(unused_return_graph(tf.constant([0.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3b245",
   "metadata": {},
   "source": [
    "### tf.function의 모범 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e892b",
   "metadata": {},
   "source": [
    "`tf.function`으로 시험용 함수를 사용하면서 즉시 실행에서 그래프 실행으로 이동하는 과정 체험 가능\n",
    "\n",
    "* `tf.config.run_functions_eagerly` : 즉시 실행과 그래프 실행 사이에 조기에 자주 전환하여 두 모드가 서로 달라지는지, 언제 달라지는지 정확하게 파악 가능\n",
    "\n",
    "\n",
    "* `tf.Variable` : Python 함수 외부에서 실행하고, 수정은 내부에서 수행함. keras.layers, keras.Model 및 tf.optimizers와 같이 tf.Variable을 사용하는 객체의 경우도 마찬가지\n",
    "\n",
    "\n",
    "* 외부 Python 변수에 의존하는 함수를 작성하지 말아야 함 (`tf.Variable`과 Keras 객체 제외)\n",
    "\n",
    "\n",
    "* 텐서 및 기타 TensorFlow 유형을 입력으로 사용하는 함수를 작성하는 것 좋음. 다른 객체 유형을 전달할 수 있지만 주의하기 !\n",
    "\n",
    "\n",
    "* 성능 이점을 극대화 하기 위해, `tf.Function` 하에서 계산이 가능한 한 많이 포함되도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b490d",
   "metadata": {},
   "source": [
    "## 속도 향상 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138b732",
   "metadata": {},
   "source": [
    "`tf.function`\n",
    "- 기본적으로 속도 향상을 하지만, 정도는 실행하는 계산의 종류에 따라 다름\n",
    "- 작은 계산의 경우, 그래프를 호출하는 오버헤드에 지배될 수 있음\n",
    "\n",
    "[참고] 코드가 TensorFlow 제어 흐름에서 과중하고 작은 텐서를 많이 사용하는 경우, 성능 개선의 효과를 높이기 위해 `tf.function(jit_compile=True)`를 시도해볼 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaaf20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
    "\n",
    "def power(x, y):\n",
    "    result = tf.eye(10, dtype=tf.dtypes.int32)\n",
    "    for _ in range(y):\n",
    "        result = tf.matmul(x, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b9f90ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution: 4.686657600001126 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72e611d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution: 0.7170433999999659 seconds\n"
     ]
    }
   ],
   "source": [
    "power_as_graph = tf.function(power)\n",
    "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7cafe2",
   "metadata": {},
   "source": [
    "### 성능과 상충 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cb8d8",
   "metadata": {},
   "source": [
    "* 그래프는 속도를 높일 수 있지만 오버헤드 발생 가능 (그래프 생성이 실행보다 오래 걸릴 수도?)\n",
    "    - 이 경우, 트레이싱으로 인해 느려질 수 있음\n",
    "    \n",
    "    \n",
    "* 모델 크기에 관계없이, 빈번한 추적은 피하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399d16e",
   "metadata": {},
   "source": [
    "## Function은 언제 트레이싱하나?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e154ac",
   "metadata": {},
   "source": [
    "* Function은 트레이싱 할 때마다 print 문을 실행함\n",
    "\n",
    "\n",
    "* 새 Python 인수는 항상 새 그래프 생성을 트리거하므로 추가 트레이싱이 발생함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bd29f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def a_function_with_python_side_effect(x):\n",
    "    print(\"Tracing!\") # An eager-only side effect.\n",
    "    return x * x + tf.constant(2)\n",
    "\n",
    "# This is traced the first time.\n",
    "print(a_function_with_python_side_effect(tf.constant(2)))\n",
    "\n",
    "# The second time through, you won't see the side effect.\n",
    "print(a_function_with_python_side_effect(tf.constant(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a83cc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing!\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "Tracing!\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This retraces each time the Python argument changes,\n",
    "# as a Python argument could be an epoch count or other\n",
    "# hyperparameter.\n",
    "print(a_function_with_python_side_effect(2))\n",
    "print(a_function_with_python_side_effect(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "til"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
