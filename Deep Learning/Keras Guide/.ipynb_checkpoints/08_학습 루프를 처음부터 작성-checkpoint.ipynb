{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daf323e33b84"
   },
   "source": [
    "# 훈련 루프 처음부터 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-hub-nightly in c:\\users\\phi49\\anaconda3\\lib\\site-packages (0.14.0.dev202306290710)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\phi49\\anaconda3\\lib\\site-packages (from tf-hub-nightly) (4.23.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\phi49\\anaconda3\\lib\\site-packages (from tf-hub-nightly) (1.24.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\phi49\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tf-hub-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras의 기본 학습 및 평가 루프\n",
    "\n",
    "Keras는 기본 학습 및 평가 루프인 `fit()`, `evaluate()`을 제공\n",
    "\n",
    "- 일반적으로 `fit()`은 Model 클래스를 하위 클래스로 만들고, 반복적으로 호출되는 고유한 `train_step()` 메서드를 구현함\n",
    "- 그런데, 훈련 및 평가에 대한 매우 낮은 수준의 제어를 원하면 자체 훈련 및 평가 루프를 처음부터 작성해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientTape 사용하기: 첫 번째 엔드 투 엔드 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GradientTape` 범위 내에서 모델 호출 시, 손실 값과 관련하여 레이어의 학습가능한 가중치의 그래디언트를 가져올 수 있음\n",
    "\n",
    "\n",
    "- 옵티마이저 인스턴스 : 변수 업데이트 가능 (`model.trainable_weights`를 사용해 가져올 수 있음)\n",
    "- 예) MNIST 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 학습 루프가 있는 미니 배치 그래디언트를 사용하여 모델 훈련\n",
    "\n",
    "- 옵티마이저, 손실 함수, 데이터세트 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 784))\n",
    "x_test = np.reshape(x_test, (-1, 784))\n",
    "\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 루프 과정\n",
    "\n",
    "- Epoch를 반복하는 `for` 루프를 연다\n",
    "- 각 epoch에 대해 데이터세트를 배치 단위로 반복하는 `for` 루프를 연다\n",
    "- 각 배치에 대해 `GradientTape()` 범위를 연다\n",
    "- 이 범위 내에서 모델(순방향 전달)을 호출하고 손실을 계산한다\n",
    "- 범위 외부에서 손실에 대한 모델 가중치의 그래디언트를 검색한다\n",
    "- 마지막으로 옵티마이저를 사용하여 그래디언트를 기반으로 모델의 가중치를 업데이트한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 181.3130\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 1.1341\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 1.4639\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.8485\n",
      "Seen so far: 38464 samples\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 1.2408\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.9118\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.8196\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.5297\n",
      "Seen so far: 38464 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    \n",
    "    # 데이터셋의 배치에 대해 반복\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "        # 각 배치에 대해 GradientTape() 범위를 엶 (자동 미분 가능)\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # 이 범위 내에서 모델 (순방향 전달) 호출하고, GradientTape에서 기록\n",
    "            logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "            # 미니배치 동안의 손실 계산\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "        # 범위 외부에서 손실에 대한 모델 가중치의 그래디언트 검색\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # 옵티마이저를 사용해 그래디언트를 기반으로 모델 가중치 업데이트\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메트릭 로우 레벨(low-level) 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 루프에 메트릭 모니터링 추가 (내장 메트릭은 쉽게 재사용 가능)\n",
    "\n",
    "- 루프 시작 시 메트릭 인스턴스 화\n",
    "- 각 배치 후에 `metric.update_state()`를 호출\n",
    "- 메트릭의 현재 값을 표시해야 하는 경우 {code 0}matric.result(){/code 0}를 호출\n",
    "- 메트릭의 상태를 삭제해야 할 경우(일반적으로 Epoch 종료 시) `metric.reset_states()`를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Prepare the metric. ★\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 및 평가 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 122.8096\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 1.6723\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 1.1608\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.5826\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.7046\n",
      "Validation acc: 0.8200\n",
      "Time taken: 22.03s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.6578\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.5854\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.4829\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.4323\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.8344\n",
      "Validation acc: 0.8666\n",
      "Time taken: 21.89s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        # 미분을 위한 GradientTape 적용\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 1) 예측\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # 2) loss 계산\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        # 3) 그래디언트 계산\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # 4) 오차역전파 - weight 업데이트\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # 각 배치 후에 metric.update_state 호출하여 training metric 업데이트\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # 각 에포크가 끝나면 training metrics는 삭제 (reset_states())\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.function으로 학습 단계 가속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 2의 기본 런타임은 '즉시 실행'\n",
    "\n",
    "**이점: 디버깅에 유용, 그래프 컴파일에 유용**\n",
    "\n",
    "- 계산을 정적 그래프로 설명하여 프레임워크로 전역 성능 최적화 적용 가능\n",
    "- 단, 프레임워크가 다음에 무엇이 올지 모르는 상태로 탐욕적으로 하나씩 실행하도록 할 때는 불가능\n",
    "\n",
    "**사용법: `@tf.function` 데코레이터를 추가하면 끝!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일된 학습 단계로 학습 루프 다시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.4079\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.6054\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.6789\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.9066\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.8679\n",
      "Validation acc: 0.8804\n",
      "Time taken: 3.75s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.5085\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.3017\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.9116\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.5044\n",
      "Seen so far: 38464 samples\n",
      "Training acc over epoch: 0.8849\n",
      "Validation acc: 0.8913\n",
      "Time taken: 2.40s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델에서 추적한 손실의 로우 레벨 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`self.add_loss(value)` : 호출하는 레이어로 순방향 전달을 수행하는 동안 생성된 손실을 재귀적으로 추적\n",
    "\n",
    "`model.losses` : Scalar 손실 값의 결과 목록을 알 수 있음\n",
    "\n",
    "이러한 손실 구성 요소를 사용하려면 이들을 종합한 후, 학습 단계의 기본 손실에 추가해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활동 정규화 손실 생성 레이어\n",
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(1e-2 * tf.reduce_sum(inputs))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "        # Add any extra losses created during the forward pass.\n",
    "        loss_value += sum(model.losses)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드 투 엔드 예제: GAN 학습 루프 처음부터 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN\n",
    "\n",
    "이미지 학습 데이터세트의 잠재 분포(이미지의 \"잠재 공간\")를 훈련하여 거의 실제처럼 보이는 새로운 이미지를 생성할 수 있음\n",
    "\n",
    "잠재 공간의 지점을 이미지 공간의 지점으로 매핑하는 \"생성기\" 모델<br>실제 이미지(학습 데이터 세트)와 가짜 이미지(생성기 네트워크의 출력물)를 구별할 수 있는 분류자인 \"판별기\" 모델의 두 부분으로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN 학습 루프**\n",
    "\n",
    "- 판별기 훈련\n",
    "    - 잠재 공간에 무작위 지점 배치 샘플링\n",
    "    - 생성기 모델로 지점을 가짜 이미지로 바꿈\n",
    "    - 실제 이미지 배치를 가져와 생성된 이미지와 결합\n",
    "    - 생성된 이미지와 실제 이미지 분류를 위한 판별기 모델 훈련\n",
    "\n",
    "\n",
    "- 생성기 훈련\n",
    "    - 앞의 1~3단계는 판별기와 동일\n",
    "    - 생성기 모델을 훈련시켜 판별기를 속이고, 가짜 이미지를 진짜로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*가짜 숫자와 실제 숫자를 구분하기 위한 판별기 생성*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 128)               0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74625 (291.50 KB)\n",
      "Trainable params: 74625 (291.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*잠재 벡터를 형태 (28, 28, 1)(MNIST 숫자를 나타냄)의 출력으로 바꾸는 생성기 네트워크 생성*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*훈련 루프*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate one optimizer for the discriminator and another for the generator\n",
    "# 판별기 모델 (Discriminative), 생성기 (Generative) 모델\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    # 잠재 공간에 무작위 지점 배치 샘플링\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # 가짜 이미지로 바꿈\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # 실제 이미지와 생성 이미지 결합\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "\n",
    "    # Train the discriminator (판별기 모델 훈련)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(combined_images)\n",
    "        d_loss = loss_fn(labels, predictions)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (판별기 모델의 가중치는 업데이트 하지 않음)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "    return d_loss, g_loss, generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*이미지 배치에서 train_step을 반복적으로 호출하여 GAN을 학습*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start epoch 0\n",
      "discriminator loss at step 0: 0.61\n",
      "adversarial loss at step 0: 0.77\n",
      "\n",
      "Start epoch 1\n",
      "discriminator loss at step 0: 0.54\n",
      "adversarial loss at step 0: 0.84\n",
      "\n",
      "Start epoch 2\n",
      "discriminator loss at step 0: 0.47\n",
      "adversarial loss at step 0: 0.72\n",
      "\n",
      "Start epoch 3\n",
      "discriminator loss at step 0: 0.40\n",
      "adversarial loss at step 0: 0.74\n",
      "\n",
      "Start epoch 4\n",
      "discriminator loss at step 0: 0.37\n",
      "adversarial loss at step 0: 0.78\n",
      "\n",
      "Start epoch 5\n",
      "discriminator loss at step 0: 0.34\n",
      "adversarial loss at step 0: 0.83\n",
      "\n",
      "Start epoch 6\n",
      "discriminator loss at step 0: 0.31\n",
      "adversarial loss at step 0: 0.93\n",
      "\n",
      "Start epoch 7\n",
      "discriminator loss at step 0: 0.26\n",
      "adversarial loss at step 0: 1.08\n",
      "\n",
      "Start epoch 8\n",
      "discriminator loss at step 0: 0.21\n",
      "adversarial loss at step 0: 1.30\n",
      "\n",
      "Start epoch 9\n",
      "discriminator loss at step 0: 0.17\n",
      "adversarial loss at step 0: 1.61\n",
      "\n",
      "Start epoch 10\n",
      "discriminator loss at step 0: 0.19\n",
      "adversarial loss at step 0: 1.82\n",
      "\n",
      "Start epoch 11\n",
      "discriminator loss at step 0: 0.25\n",
      "adversarial loss at step 0: 1.91\n",
      "\n",
      "Start epoch 12\n",
      "discriminator loss at step 0: 0.48\n",
      "adversarial loss at step 0: 1.66\n",
      "\n",
      "Start epoch 13\n",
      "discriminator loss at step 0: 0.34\n",
      "adversarial loss at step 0: 1.73\n",
      "\n",
      "Start epoch 14\n",
      "discriminator loss at step 0: 0.21\n",
      "adversarial loss at step 0: 2.06\n",
      "\n",
      "Start epoch 15\n",
      "discriminator loss at step 0: 0.13\n",
      "adversarial loss at step 0: 2.40\n",
      "\n",
      "Start epoch 16\n",
      "discriminator loss at step 0: 0.12\n",
      "adversarial loss at step 0: 2.55\n",
      "\n",
      "Start epoch 17\n",
      "discriminator loss at step 0: 0.28\n",
      "adversarial loss at step 0: 2.05\n",
      "\n",
      "Start epoch 18\n",
      "discriminator loss at step 0: 0.50\n",
      "adversarial loss at step 0: 1.09\n",
      "\n",
      "Start epoch 19\n",
      "discriminator loss at step 0: 0.53\n",
      "adversarial loss at step 0: 1.09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare the dataset. We use both the training & test MNIST digits.\n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255.0\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "epochs = 20\n",
    "save_dir = \"./\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "\n",
    "    for step, real_images in enumerate(dataset):\n",
    "        # Train the discriminator & generator on one batch of real images.\n",
    "        d_loss, g_loss, generated_images = train_step(real_images)\n",
    "\n",
    "        # Logging.\n",
    "        if step % 200 == 0:\n",
    "            # Print metrics\n",
    "            print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n",
    "            print(\"adversarial loss at step %d: %.2f\" % (step, g_loss))\n",
    "\n",
    "            # Save one generated image\n",
    "            img = tf.keras.preprocessing.image.array_to_img(\n",
    "                generated_images[0] * 255.0, scale=False\n",
    "            )\n",
    "            img.save(os.path.join(save_dir, \"generated_img\" + str(step) + \".png\"))\n",
    "\n",
    "        # To limit execution time we stop after 10 steps.\n",
    "        # Remove the lines below to actually train the model!\n",
    "        if step > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "writing_a_training_loop_from_scratch.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
