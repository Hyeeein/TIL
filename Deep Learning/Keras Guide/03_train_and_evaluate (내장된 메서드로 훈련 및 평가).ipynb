{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b12f27b",
   "metadata": {},
   "source": [
    "## 내장된 메서드로 훈련 및 평가하기\n",
    "\n",
    "훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측(추론) 모델에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6ced52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phi49\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838465a7",
   "metadata": {},
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b30629",
   "metadata": {},
   "source": [
    "* 데이터를 모델의 내장 훈련 루프로 전달할 때는 NumPy 배열 또는 `tf.data Dataset` 객체를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ede64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "\n",
    "# Dense Layer: 입력 레이어 1개, 은닉 레이어 2개, 출력 레이더 1개로 구성 (완전 연결층이라고 정의)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd829608",
   "metadata": {},
   "source": [
    "**일반적인 엔드 투 엔드 워크플로**\n",
    "\n",
    "1. 훈련\n",
    "2. 원래 훈련 데이터에서 생성된 홀드아웃 세트에 대한 유효성 검사\n",
    "3. 테스트 데이터에 대한 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00aeb57",
   "metadata": {},
   "source": [
    "예) 다음 예시는 MNIST 데이터세트를 NumPy 배열로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c0b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 데이터를 NumPy 배열로 변환\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Validation을 위한 10000개의 샘플 보류\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0a326",
   "metadata": {},
   "source": [
    "훈련 구성 (최적화, 손실, 메트릭) 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e388074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # 최적화 (Optimizer)\n",
    "    # 손실함수 (SparseCategoricalCrossentropy)\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # 메트릭 (List of metrics to monitor)\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a3cef",
   "metadata": {},
   "source": [
    "`fit()`을 호출하여 데이터를 배치로 분할하고, `epochs`에 대해 전체 데이터세트를 반복처리하여 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19827c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3336 - sparse_categorical_accuracy: 0.9043 - val_loss: 0.1688 - val_sparse_categorical_accuracy: 0.9524\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9594\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # 각 에포크가 끝날 때 손실, 메트릭을 모니터링하기 위해 일부 validation 은 통과\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab4849",
   "metadata": {},
   "source": [
    "반환되는 `history` 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cefa162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.33363837003707886, 0.1597750037908554],\n",
       " 'sparse_categorical_accuracy': [0.9042999744415283, 0.9525399804115295],\n",
       " 'val_loss': [0.16875500977039337, 0.14108921587467194],\n",
       " 'val_sparse_categorical_accuracy': [0.9524000287055969, 0.9593999981880188]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796631da",
   "metadata": {},
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ad6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1428 - sparse_categorical_accuracy: 0.9598\n",
      "test loss, test acc: [0.14275218546390533, 0.9598000049591064]\n",
      "Generate predictions for 3 samples\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "predictions shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# `evaluate`을 사용하여 테스트 데이터에 대한 모델 평가\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# 새로운 데이터를 사용하여 예측\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf2f16",
   "metadata": {},
   "source": [
    "## compile() 메서드 : 손실, 메트릭 및 최적화 프로그램 지정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d6d5e",
   "metadata": {},
   "source": [
    "`fit()`으로 모델 훈련을 시키기 위해 손실 함수, 최적화 프로그램, 그리고 선택적으로 모니터링할 일부 메트릭을 지정해야 함\n",
    "\n",
    "이러한 내용들은 `compile()` 메서드에 대한 인수로 모델에 전달해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8adf005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844da54",
   "metadata": {},
   "source": [
    "`metrics` 인수는 목록이어야 함 (모델 메트릭 수는 얼마든지 가능)\n",
    "\n",
    "\n",
    "모델에 여러 개의 출력이 있는 경우, 각 출력에 대해 로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19279438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12388cf6",
   "metadata": {},
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416534e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일하지 않은 모델\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 컴파일 한 모델\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638f249",
   "metadata": {},
   "source": [
    "### 많은 내장 최적화 프로그램, 손실 및 메트릭 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869e766",
   "metadata": {},
   "source": [
    "* 최적화 프로그램 : `SGE()`, `RMSprop()`, `Adam()`, ...\n",
    "\n",
    "\n",
    "* 손실 : `MeanSquaredError()`, `KLDivergence()`, `CosineSimilarity()`, ...\n",
    "\n",
    "\n",
    "* 메트릭 : `AUC()`, `Precision()`, `Recall()`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a8967",
   "metadata": {},
   "source": [
    "### 사용자 정의 손실"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c109c4f",
   "metadata": {},
   "source": [
    "사용자 정의 손실을 만들어야 하는 경우, Keras는 두 가지 방법 제공\n",
    "\n",
    "\n",
    "1. 입력 y_true 및 y_pred를 받아들이는 함수를 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56212954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23a237f40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 데이터와 예측 사이의 오차에 대해 평균 제곱을 계산하는 손실함수\n",
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# MSE를 사용하기 위해 원-핫 인코딩\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e0fa8",
   "metadata": {},
   "source": [
    "2. y_true 및 y_pred 이외의 매개변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 하위 클래스화하고 다음 두 메서드를 구현\n",
    "\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개변수를 받아들임\n",
    "\n",
    "\n",
    "- `call(self, y_true, y_pred)` : 목표(y_true)와 모델 예측(y_pred)을 사용하여 모델의 손실을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb83c0",
   "metadata": {},
   "source": [
    "오차의 평균 제곱을 사용하려고 하지만 예측 값을 0.5에서 멀어지게 하는 항이 추가되었다고 가정 (범주형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정) \n",
    "\n",
    "\n",
    "이렇게 하면 모델이 너무 확신을 갖지 않게 하는 인센티브가 *과적합*을 줄이는 데 도움이 될 수 있음 (단, 시도 하기 전까진 효과가 있는지 알 수 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3245603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23d384730>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))  # 예측 값을 0.5에서 멀어지게 함\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f58b0",
   "metadata": {},
   "source": [
    "### 사용자 정의 메트릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf2ec7",
   "metadata": {},
   "source": [
    "`tf.keras.metrics.Metric` : API의 일부가 아닌 메트릭이 필요한 경우, 이 클래스를 하위 클래스화하여 사용자 정의 메트릭 생성 가능\n",
    "\n",
    "\n",
    "* *아래의 4가지 메서드 구현 필요*\n",
    "\n",
    "    1. `__init__(self)` : 메트릭에 대한 상태 변수 생성\n",
    "    2. `update_state(self, y_true, y_pred, sample_weight=None)` : y_true 목표값과 y_pred 모델 예측값을 사용하여 상태 변수 업데이트\n",
    "    3. `result(self)` : 상태 변수를 사용하여 최종 경과 계산\n",
    "    4. `reset_state(self)` : 메트릭 상태를 다시 초기화 함\n",
    "\n",
    "\n",
    "* 상태 업데이트와 결과 계산은 개별적으로 수행 -> 일부의 경우, 결과 계산 부담이 크고, 주기적으로 수행되기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca127ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3388 - categorical_true_positives: 45150.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1608 - categorical_true_positives: 47664.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1183 - categorical_true_positives: 48210.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23e6d40d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 올바르게 분류된 샘플 수를 계산하는 메트릭 구현 예제\n",
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    # 메트릭에 대한 상태 변수 생성\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    # 상태 변수 업데이트 (y_true, y_pred 사용)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "    \n",
    "    # 상태 변수를 사용하여 최종 경과 계산\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    # 메트릭 상태를 다시 초기화\n",
    "    def reset_state(self):\n",
    "        # epoch 시작마다 메트릭 상태 초기화\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "model = get_uncompiled_model()  # 컴파일 되지 않은 모델 함수\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48f69f",
   "metadata": {},
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9bcef",
   "metadata": {},
   "source": [
    "* 거의 대부분의 손실과 메트릭은 `y_true`와 `y_pred`에서 계산할 수 있지만 모두 그런 것은 아님\n",
    "\n",
    "\n",
    "* 이러한 경우, 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출 가능<br> 추가된 손실은 훈련 중 \"주요\" 손실(compile()로 전달되는 손실)에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6608904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.4998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23a197c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 활동 정규화를 추가하는 간단한 예\n",
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Layer에 활동 정규화 삽입\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# 정규화 요소를 추가했으므로, 보여지는 손실은 전보다 더 커짐\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e749d9",
   "metadata": {},
   "source": [
    "* `add_metric()`을 사용하여 메트릭 값 로깅에 대해 같은 작업 수행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbaf4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3413 - std_of_activation: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23a177610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # `aggregation`은 각 epoch마다 각 배치 값을 합치는 방법을 정의\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614510a",
   "metadata": {},
   "source": [
    "* Functional API에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)`을 호출 가능\n",
    "    - `add_loss()`를 통해, 손실 전달하면 모델에 이미 최소화할 수 있는 손실이 있으므로 손실 함수 없이 `compile()` 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e96339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5049 - std_of_activation: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c2383bcc10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Function API\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcb679",
   "metadata": {},
   "source": [
    "`LogisticEndpoint` 레이어 : 입력으로  targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적\n",
    "\n",
    "- `add_metric()`을 통해 분류 정확도도 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92a5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # training-time loss 값을 계산하고\n",
    "        # 'self.add_loss()'를 사용한 레이어를 추가\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "        \n",
    "        # 메트릭으로 정확도를 기록하고\n",
    "        # 'self.add_metric()'을 사용하여 레이어에 추가\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # 추론 시간 예측 텐서 반환 (.predict()에 대해)\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f4384",
   "metadata": {},
   "source": [
    "* loss 인수 없이 컴파일된 두 개의 입력(입력 data 및 targets)이 있는 모델에서 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dc28011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 321ms/step - loss: 1.0510 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c23850dc10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d1ef9",
   "metadata": {},
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a4919",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca4367",
   "metadata": {},
   "source": [
    "## tf.data 데이터세트로부터 훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4de8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc60005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4e67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c6243",
   "metadata": {},
   "source": [
    "### 유효성 검사 데이터세트 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced32015",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e53830",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d322e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4268d10",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25342683",
   "metadata": {},
   "source": [
    "## 지원되는 다른 입력 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3ba7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d8c55fe",
   "metadata": {},
   "source": [
    "## keras.utils.Sequence 객체를 입력으로 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab434db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a8892",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9764c",
   "metadata": {},
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530851aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d79daecc",
   "metadata": {},
   "source": [
    "### 클래스 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f327a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4053e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830682f",
   "metadata": {},
   "source": [
    "### 샘플 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea657e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f053915",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19358239",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4671d1",
   "metadata": {},
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d61155",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cb7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25b0394",
   "metadata": {},
   "source": [
    "## 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c3b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ebe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf90fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20b768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a0f87b",
   "metadata": {},
   "source": [
    "### 많은 내장 콜백 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60d5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7063d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4a9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a2097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffb5a4cb",
   "metadata": {},
   "source": [
    "### 고유한 콜백 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150c154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4db79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ebc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3dd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf9248c4",
   "metadata": {},
   "source": [
    "## 모델 검사점 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b85b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac9d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98946f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7860104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "005d18b2",
   "metadata": {},
   "source": [
    "## 학습률 일정 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7f754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613689b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25205c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38da2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5047af0c",
   "metadata": {},
   "source": [
    "### 최적화 프로그램으로 일정 전달하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e8a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e50dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0435e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc4dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c44cb672",
   "metadata": {},
   "source": [
    "### 콜백을 사용하여 동적 학습률 일정 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005e4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e10cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ac887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a5079f",
   "metadata": {},
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67622622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c425dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a58ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48537263",
   "metadata": {},
   "source": [
    "### TensorBoard 콜백 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caee238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04310519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b516b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c3336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea8b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0c275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e65681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc44c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd26d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a08afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "til"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
