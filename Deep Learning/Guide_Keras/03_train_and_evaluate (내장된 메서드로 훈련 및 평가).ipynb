{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b12f27b",
   "metadata": {},
   "source": [
    "## 내장된 메서드로 훈련 및 평가하기\n",
    "\n",
    "훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측(추론) 모델에 대한 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c6ced52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838465a7",
   "metadata": {},
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b30629",
   "metadata": {},
   "source": [
    "* 데이터를 모델의 내장 훈련 루프로 전달할 때는 NumPy 배열 또는 `tf.data Dataset` 객체를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ede64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "\n",
    "# Dense Layer: 입력 레이어 1개, 은닉 레이어 2개, 출력 레이더 1개로 구성 (완전 연결층이라고 정의)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd829608",
   "metadata": {},
   "source": [
    "**일반적인 엔드 투 엔드 워크플로**\n",
    "\n",
    "1. 훈련\n",
    "2. 원래 훈련 데이터에서 생성된 홀드아웃 세트에 대한 유효성 검사\n",
    "3. 테스트 데이터에 대한 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00aeb57",
   "metadata": {},
   "source": [
    "예) 다음 예시는 MNIST 데이터세트를 NumPy 배열로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c0b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# 데이터를 NumPy 배열로 변환\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Validation을 위한 10000개의 샘플 보류\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0a326",
   "metadata": {},
   "source": [
    "훈련 구성 (최적화, 손실, 메트릭) 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e388074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # 최적화 (Optimizer)\n",
    "    # 손실함수 (SparseCategoricalCrossentropy)\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # 메트릭 (List of metrics to monitor)\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a3cef",
   "metadata": {},
   "source": [
    "`fit()`을 호출하여 데이터를 배치로 분할하고, `epochs`에 대해 전체 데이터세트를 반복처리하여 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19827c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.1962 - val_sparse_categorical_accuracy: 0.9437\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1579 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1482 - val_sparse_categorical_accuracy: 0.9572\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # 각 에포크가 끝날 때 손실, 메트릭을 모니터링하기 위해 일부 validation 은 통과\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab4849",
   "metadata": {},
   "source": [
    "반환되는 `history` 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cefa162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.337371289730072, 0.1578771024942398],\n",
       " 'sparse_categorical_accuracy': [0.9039400219917297, 0.9531999826431274],\n",
       " 'val_loss': [0.19617846608161926, 0.14819879829883575],\n",
       " 'val_sparse_categorical_accuracy': [0.9437000155448914, 0.9571999907493591]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796631da",
   "metadata": {},
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30ad6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1480 - sparse_categorical_accuracy: 0.9545\n",
      "test loss, test acc: [0.14796650409698486, 0.9545000195503235]\n",
      "Generate predictions for 3 samples\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "predictions shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# `evaluate`을 사용하여 테스트 데이터에 대한 모델 평가\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# 새로운 데이터를 사용하여 예측\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf2f16",
   "metadata": {},
   "source": [
    "## compile() 메서드 : 손실, 메트릭 및 최적화 프로그램 지정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d6d5e",
   "metadata": {},
   "source": [
    "`fit()`으로 모델 훈련을 시키기 위해 손실 함수, 최적화 프로그램, 그리고 선택적으로 모니터링할 일부 메트릭을 지정해야 함\n",
    "\n",
    "이러한 내용들은 `compile()` 메서드에 대한 인수로 모델에 전달해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8adf005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844da54",
   "metadata": {},
   "source": [
    "`metrics` 인수는 목록이어야 함 (모델 메트릭 수는 얼마든지 가능)\n",
    "\n",
    "\n",
    "모델에 여러 개의 출력이 있는 경우, 각 출력에 대해 로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19279438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12388cf6",
   "metadata": {},
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "416534e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일하지 않은 모델\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 컴파일 한 모델\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638f249",
   "metadata": {},
   "source": [
    "### 많은 내장 최적화 프로그램, 손실 및 메트릭 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869e766",
   "metadata": {},
   "source": [
    "* 최적화 프로그램 : `SGD()`, `RMSprop()`, `Adam()`, ...\n",
    "\n",
    "\n",
    "* 손실 : `MeanSquaredError()`, `KLDivergence()`, `CosineSimilarity()`, ...\n",
    "\n",
    "\n",
    "* 메트릭 : `AUC()`, `Precision()`, `Recall()`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a8967",
   "metadata": {},
   "source": [
    "### 사용자 정의 손실"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c109c4f",
   "metadata": {},
   "source": [
    "사용자 정의 손실을 만들어야 하는 경우, Keras는 두 가지 방법 제공\n",
    "\n",
    "\n",
    "1. 입력 y_true 및 y_pred를 받아들이는 함수를 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56212954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779d6f59a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 데이터와 예측 사이의 오차에 대해 평균 제곱을 계산하는 손실함수\n",
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# MSE를 사용하기 위해 원-핫 인코딩\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e0fa8",
   "metadata": {},
   "source": [
    "2. y_true 및 y_pred 이외의 매개변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 하위 클래스화하고 다음 두 메서드를 구현\n",
    "\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개변수를 받아들임\n",
    "\n",
    "\n",
    "- `call(self, y_true, y_pred)` : 목표(y_true)와 모델 예측(y_pred)을 사용하여 모델의 손실을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb83c0",
   "metadata": {},
   "source": [
    "오차의 평균 제곱을 사용하려고 하지만 예측 값을 0.5에서 멀어지게 하는 항이 추가되었다고 가정 (범주형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정) \n",
    "\n",
    "\n",
    "이렇게 하면 모델이 너무 확신을 갖지 않게 하는 인센티브가 *과적합*을 줄이는 데 도움이 될 수 있음 (단, 시도 하기 전까진 효과가 있는지 알 수 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3245603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779da85670>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))  # 예측 값을 0.5에서 멀어지게 함\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f58b0",
   "metadata": {},
   "source": [
    "### 사용자 정의 메트릭"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf2ec7",
   "metadata": {},
   "source": [
    "`tf.keras.metrics.Metric` : API의 일부가 아닌 메트릭이 필요한 경우, 이 클래스를 하위 클래스화하여 사용자 정의 메트릭 생성 가능\n",
    "\n",
    "\n",
    "* *아래의 4가지 메서드 구현 필요*\n",
    "\n",
    "    1. `__init__(self)` : 메트릭에 대한 상태 변수 생성\n",
    "    2. `update_state(self, y_true, y_pred, sample_weight=None)` : y_true 목표값과 y_pred 모델 예측값을 사용하여 상태 변수 업데이트\n",
    "    3. `result(self)` : 상태 변수를 사용하여 최종 경과 계산\n",
    "    4. `reset_state(self)` : 메트릭 상태를 다시 초기화 함\n",
    "\n",
    "\n",
    "* 상태 업데이트와 결과 계산은 개별적으로 수행 -> 일부의 경우, 결과 계산 부담이 크고, 주기적으로 수행되기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca127ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3461 - categorical_true_positives: 45041.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1591 - categorical_true_positives: 47641.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1170 - categorical_true_positives: 48234.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779de035b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 올바르게 분류된 샘플 수를 계산하는 메트릭 구현 예제\n",
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    # 메트릭에 대한 상태 변수 생성\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    # 상태 변수 업데이트 (y_true, y_pred 사용)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "    \n",
    "    # 상태 변수를 사용하여 최종 경과 계산\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    # 메트릭 상태를 다시 초기화\n",
    "    def reset_state(self):\n",
    "        # epoch 시작마다 메트릭 상태 초기화\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "model = get_uncompiled_model()  # 컴파일 되지 않은 모델 함수\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48f69f",
   "metadata": {},
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9bcef",
   "metadata": {},
   "source": [
    "* 거의 대부분의 손실과 메트릭은 `y_true`와 `y_pred`에서 계산할 수 있지만 모두 그런 것은 아님\n",
    "\n",
    "\n",
    "* 이러한 경우, 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출 가능<br> 추가된 손실은 훈련 중 \"주요\" 손실(compile()로 전달되는 손실)에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6608904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177bd2a3a00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 활동 정규화를 추가하는 간단한 예\n",
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Layer에 활동 정규화 삽입\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# 정규화 요소를 추가했으므로, 보여지는 손실은 전보다 더 커짐\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e749d9",
   "metadata": {},
   "source": [
    "* `add_metric()`을 사용하여 메트릭 값 로깅에 대해 같은 작업 수행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acbaf4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3516 - std_of_activation: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779e0a6f40>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # `aggregation`은 각 epoch마다 각 배치 값을 합치는 방법을 정의\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614510a",
   "metadata": {},
   "source": [
    "* Functional API에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)`을 호출 가능\n",
    "    - `add_loss()`를 통해, 손실 전달하면 모델에 이미 최소화할 수 있는 손실이 있으므로 손실 함수 없이 `compile()` 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1e96339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5171 - std_of_activation: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779e1f6fd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Function API\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcb679",
   "metadata": {},
   "source": [
    "`LogisticEndpoint` 레이어 : 입력으로  targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적\n",
    "\n",
    "- `add_metric()`을 통해 분류 정확도도 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e92a5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # training-time loss 값을 계산하고\n",
    "        # 'self.add_loss()'를 사용한 레이어를 추가\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "        \n",
    "        # 메트릭으로 정확도를 기록하고\n",
    "        # 'self.add_metric()'을 사용하여 레이어에 추가\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # 추론 시간 예측 텐서 반환 (.predict()에 대해)\n",
    "        return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f4384",
   "metadata": {},
   "source": [
    "* loss 인수 없이 컴파일된 두 개의 입력(입력 data 및 targets)이 있는 모델에서 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dc28011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 371ms/step - loss: 0.9727 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779e3418e0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d1ef9",
   "metadata": {},
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a4919",
   "metadata": {},
   "source": [
    "1. `validation_data` 인수를 사용하여 NumPy 배열의 튜플 `(x_val, y_val)`을 모델에 전달하여 각 epoch 끝에서 유효성 검사 손실과 유효성 검사 메트릭을 평가\n",
    "\n",
    "\n",
    "2. 인수 `validation_split`를 사용하여 검증 목적으로 훈련 데이터의 일부를 자동으로 예약 가능.<br> *인수 값은 검증을 위해 예약할 데이터 비율을 나타내므로, 0보다 크고 1보다 작은 값으로 설정해야 함 <br> (예: validation_split=0.2는 \"유효성 검사를 위해 데이터의 20%를 사용\"한다는 의미)* <br> => NumPy 데이터로 훈련할 때만 사용 가능 !!\n",
    "\n",
    "\n",
    "- 유효성 계산 방법 : 셔플링 전에 `fit()` 호출로 수신한 배열의 마지막 x% 샘플을 가져오는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efd6b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.8947 - val_loss: 0.2353 - val_sparse_categorical_accuracy: 0.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779f6d3d00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca4367",
   "metadata": {},
   "source": [
    "## tf.data 데이터세트로부터 훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4de8f",
   "metadata": {},
   "source": [
    "데이터가 `tf.data.Dataset` 객체의 형태로 제공되는 경우\n",
    "\n",
    "- `tf.data` API는 빠르고 확장 가능한 방식으로, 데이터를 로드하고 사전 처리하기 위한 세트\n",
    "- `Dataset` 인스턴스를 메서드 `fit()`, `evaluate()`, `predict()`로 직접 전달 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fc60005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9543\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.1128 - sparse_categorical_accuracy: 0.9665\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.11762889474630356,\n",
       " 'sparse_categorical_accuracy': 0.9635999798774719}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# 먼저, training Dataset 인스턴스 만듦 (MNIST 데이터를 사용할 것)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# 데이터셋이 이미 배치되었으므로, 우리는 배치사이즈만큼 지나갈 수 없음\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed4e67",
   "metadata": {},
   "source": [
    "데이터 세트는 각 epoch의 끝에서 재설정되므로, 다음 epoch에서 재사용 가능\n",
    "\n",
    "- 특정 배치 수에 대해서만 훈련을 실행하려면 다음 epoch로 이동하기 전에 이 데이터세트를 사용하여 모델이 실행해야 하는 훈련 단계의 수를 지정하는 `steps_per_epoch` 인수를 전달할 수 있음\n",
    "\n",
    "\n",
    "- But, 이렇게 하면 각 epoch가 끝날 때 데이터세트가 재설정되지 않고 다음 배치를 계속 가져오게 됨. 무한 반복되는 데이터세트가 아니라면 결국 데이터세트의 데이터가 고갈."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0129f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 0.7859 - sparse_categorical_accuracy: 0.7911\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3846 - sparse_categorical_accuracy: 0.8878\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3406 - sparse_categorical_accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779f832e50>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c6243",
   "metadata": {},
   "source": [
    "### 유효성 검사 데이터세트 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced32015",
   "metadata": {},
   "source": [
    "`fit()`에서 `Dataset` 인스턴스를 `validation_data` 인수로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91a2cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779f4532b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e53830",
   "metadata": {},
   "source": [
    "각 epoch가 끝날 때, 모델은 검증 데이터세트를 반복하고 유효성 검사 손실 및 검증 메트릭을 계산함\n",
    "\n",
    "특정 배치 수에 대해서만 유효성 검사를 실행하려면 유효성 검사를 중단하고 다음 epoch로 넘어가기 전에 유효성 검사 데이터세트에서 모델이 실행해야 하는 유효성 검사 단계의 수를 지정하는 `validation_steps` 인수를 전달할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5d322e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3416 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.9031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a3bd1a30>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4268d10",
   "metadata": {},
   "source": [
    "유효성 검사 데이터세트 : 사용 후 매번 재설정되므로 epoch마다 항상 동일한 샘플을 평가하게 됨\n",
    "\n",
    "- 인수 `validation_split`(훈련 데이터로부터 홀드아웃 세트 생성)는 `Dataset` 객체로 훈련할 때는 지원되지 않는데, 이를 위해서는 데이터세트 샘플을 인덱싱할 수 있어야 하지만 `Dataset` API에서는 일반적으로 이것이 불가능하기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25342683",
   "metadata": {},
   "source": [
    "## 지원되는 다른 입력 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3ba7e",
   "metadata": {},
   "source": [
    "**Keras 모델을 사용하는 경우**\n",
    "\n",
    "\n",
    "- 데이터가 작고 메모리에 맞는 경우 `NumPy 입력 데이터`\n",
    "\n",
    "\n",
    "- 큰 데이터세트가 있고 분산 훈련을 수행해야 하는 경우 `Dataset 객체`\n",
    "\n",
    "\n",
    "- 큰 데이터세트가 있고 TensorFlow에서 수행할 수 없는 많은 사용자 정의 Python 측 처리를 수행해야 하는 경우(예: 데이터 로드 또는 사전 처리를 위해 외부 라이브러리에 의존하는 경우) `Sequence 객체`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c55fe",
   "metadata": {},
   "source": [
    "## keras.utils.Sequence 객체를 입력으로 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab434db",
   "metadata": {},
   "source": [
    "`keras.utils.Sequence`\n",
    "\n",
    "- 멀티 프로세싱과 잘 작동함\n",
    "- 셔플 가능 (예: `fit()`에서 `shuffle=True`를 전달하는 경우)\n",
    "\n",
    "Sequence는 두 가지 메서드 구현 필요\n",
    "\n",
    "- `__getitem__` : 완전한 배치 반환 필요, epoch 사이에서 데이터 세트를 수정하려면 `on_epoch_end` 구현 가능\n",
    "- `__len__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93ecdab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# filnames : 이미지 경로의 리스트\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# labels : 연관된 라벨들\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCIFAR10Sequence\u001b[39;00m(\u001b[43mSequence\u001b[49m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filenames, labels, batch_size):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilenames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m filenames, labels\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequence' is not defined"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# filnames : 이미지 경로의 리스트\n",
    "# labels : 연관된 라벨들\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)\n",
    "\n",
    "## 오류 발생 : Sequence 미선언 => CIFAR10Sequence 안에 있는 요소가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a8892",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9764c",
   "metadata": {},
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530851aa",
   "metadata": {},
   "source": [
    "데이터에 가중치를 부여하는 방법 : 클래스 가중치, 샘플 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79daecc",
   "metadata": {},
   "source": [
    "### 클래스 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f327a",
   "metadata": {},
   "source": [
    "`Model.fit()`에 대한 `class_weight` 인수로 사전을 전달하여 설정\n",
    "\n",
    "- 이 사전은 클래스 인덱스를 이 클래스에 속한 샘플에 사용해야 하는 가중치에 매핑\n",
    "- 샘플링을 다시 수행하지 않고, 클래스의 균형을 맞추거나 특정 클래스에 더 중요한 모델을 훈련시키는 데 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4053e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3710 - sparse_categorical_accuracy: 0.9014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a4f6cdc0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830682f",
   "metadata": {},
   "source": [
    "### 샘플 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea657e",
   "metadata": {},
   "source": [
    "세밀한 제어가 필요하거나 분류기를 빌드하지 않는 경우 사용 가능\n",
    "\n",
    "- NumPy 데이터에서 훈련하는 경우: `sample_weight` 인수를 `Model.fit()`으로 전달\n",
    "- `tf.data` 또는 다른 종류의 반복기에서 훈련하는 경우: `Yield (input_batch, label_batch, sample_weight_batch)` 튜플을 생성\n",
    "\n",
    "\"샘플 가중치\" 배열은 총 손실을 계산할 때 배치의 각 샘플에 필요한 가중치를 지정하는 숫자 배열로, 불균형적인 분류 문제에 일반적으로 사용 (거의 드러나지 않는 클래스에 더 많은 가중치를 부여한다는 개념)\n",
    "\n",
    "사용된 가중치가 1과 0인 경우, 배열은 손실 함수에 대한 마스크로 사용될 수 있음 (전체 손실에 대한 특정 샘플의 기여도를 완전히 버림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f053915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3808 - sparse_categorical_accuracy: 0.9001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a506dc10>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2ed0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3886 - sparse_categorical_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a518ecd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cd33a",
   "metadata": {
    "id": "a5f94cd76df5"
   },
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달하기\n",
    "\n",
    "입력 또는 출력이 여러 개인 모델\n",
    "\n",
    "- 형상 `(32, 32, 3)`(height, width, channels)의 이미지 입력과 형상 `(None, 10)`(timesteps, features)의 시계열 입력이 있는 다음 모델을 고려해보면\n",
    "- 이 모델은 이러한 입력의 조합으로부터 계산된 다음의 두 출력을 가짐. \"score\"(형상 `(1,)`) 및 다섯 개의 클래스에 걸친 확률 분포(형상 `(5,)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "534e48fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:58.715779Z",
     "iopub.status.busy": "2022-12-14T23:00:58.715167Z",
     "iopub.status.idle": "2022-12-14T23:00:58.778272Z",
     "shell.execute_reply": "2022-12-14T23:00:58.777659Z"
    },
    "id": "5f958449a057"
   },
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aee03f",
   "metadata": {
    "id": "df3ed34fe78b"
   },
   "source": [
    "이 모델을 플롯해 보면 여기서 수행 중인 작업을 명확하게 확인할 수 있음 (플롯에 표시된 형상이 샘플별 형상이 아니라 배치 형상임에 주목)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5499f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:58.781782Z",
     "iopub.status.busy": "2022-12-14T23:00:58.781210Z",
     "iopub.status.idle": "2022-12-14T23:00:59.028082Z",
     "shell.execute_reply": "2022-12-14T23:00:59.027299Z"
    },
    "id": "ac8c1baca9e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7914d",
   "metadata": {
    "id": "4d979e89b335"
   },
   "source": [
    "컴파일할 때 손실 함수를 목록으로 전달하여 출력마다 다른 손실을 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c8a3f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.032195Z",
     "iopub.status.busy": "2022-12-14T23:00:59.031661Z",
     "iopub.status.idle": "2022-12-14T23:00:59.046279Z",
     "shell.execute_reply": "2022-12-14T23:00:59.045630Z"
    },
    "id": "9655c0084d70"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8aa69",
   "metadata": {
    "id": "f5fc73405283"
   },
   "source": [
    "모델에 단일 손실 함수만 전달하는 경우, 모든 출력에 동일한 손실 함수가 적용 (여기서는 적합하지 않음).\n",
    "\n",
    "메트릭의 경우도 마찬가지 ,,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0881c9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.049735Z",
     "iopub.status.busy": "2022-12-14T23:00:59.049161Z",
     "iopub.status.idle": "2022-12-14T23:00:59.064951Z",
     "shell.execute_reply": "2022-12-14T23:00:59.064310Z"
    },
    "id": "b4c0c6c564bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449f803",
   "metadata": {
    "id": "4dd9fb0343cc"
   },
   "source": [
    "출력 레이어에 이름을 지정했으므로 사전을 통해 출력별 손실과 메트릭을 지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6633f237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.068267Z",
     "iopub.status.busy": "2022-12-14T23:00:59.067818Z",
     "iopub.status.idle": "2022-12-14T23:00:59.082445Z",
     "shell.execute_reply": "2022-12-14T23:00:59.081885Z"
    },
    "id": "42cb75110fc3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c0af3",
   "metadata": {
    "id": "bfd95ac0dd8b"
   },
   "source": [
    "출력이 두 개 이상인 경우 명시적 이름과 사전을 사용하는 것이 좋음\n",
    "\n",
    "`loss_weights` 인수를 사용하여 출력별 손실에 서로 다른 가중치를 부여할 수 있음 <br>\n",
    "(예를 들어, 클래스 손실에 2x의 중요도를 부여하여 이 예에서 \"score\" 손실에 우선권을 줄 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f1a0f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.085910Z",
     "iopub.status.busy": "2022-12-14T23:00:59.085295Z",
     "iopub.status.idle": "2022-12-14T23:00:59.099991Z",
     "shell.execute_reply": "2022-12-14T23:00:59.099440Z"
    },
    "id": "23a71e5f5227"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0e1b2",
   "metadata": {
    "id": "147b5f581c32"
   },
   "source": [
    "이러한 출력이 예측를 위한 것이고 훈련과는 관계가 없는 경우, 특정 출력에 대한 손실을 계산하지 않도록 선택할 수도 있dma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09a48bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.103156Z",
     "iopub.status.busy": "2022-12-14T23:00:59.102713Z",
     "iopub.status.idle": "2022-12-14T23:00:59.116828Z",
     "shell.execute_reply": "2022-12-14T23:00:59.116277Z"
    },
    "id": "6d51aa372ef4"
   },
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee96f3",
   "metadata": {
    "id": "c00d5f56d3f0"
   },
   "source": [
    "`fit()`에서 다중 입력 또는 다중 출력 모델로 데이터를 전달하는 것은 컴파일에서 손실 함수를 지정하는 것과 유사한 방식으로 작동. 즉, <strong>NumPy 배열 목록</strong>(손실 함수를 수신한 출력에 1:1 매핑) 또는 **출력 이름을 NumPy 배열에 매핑한 사전**을 전달할 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cba767d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:00:59.120073Z",
     "iopub.status.busy": "2022-12-14T23:00:59.119631Z",
     "iopub.status.idle": "2022-12-14T23:01:01.962659Z",
     "shell.execute_reply": "2022-12-14T23:01:01.961876Z"
    },
    "id": "0539da84328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 7ms/step - loss: 18.6695 - score_output_loss: 1.0530 - class_output_loss: 17.6165\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 17.5895 - score_output_loss: 0.5768 - class_output_loss: 17.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a55d8ca0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421aec90",
   "metadata": {
    "id": "e53eda8e1399"
   },
   "source": [
    "다음은 `Dataset`를 사용한 예 -> 사전 튜플을 반환해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58b34432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:01.966251Z",
     "iopub.status.busy": "2022-12-14T23:01:01.965613Z",
     "iopub.status.idle": "2022-12-14T23:01:02.435774Z",
     "shell.execute_reply": "2022-12-14T23:01:02.435100Z"
    },
    "id": "4df41a12ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 17ms/step - loss: 17.2784 - score_output_loss: 0.3327 - class_output_loss: 16.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a531c9a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038c372",
   "metadata": {
    "id": "05c792cd43a4"
   },
   "source": [
    "## 콜백 사용하기\n",
    "\n",
    "Keras의 콜백은 훈련 중 다른 시점(epoch의 시작, 배치의 끝, epoch의 끝 등)에서 호출되며 다음과 같은 특정 동작을 구현하는 데 사용할 수 있는 객체입니다.\n",
    "\n",
    "- 훈련 중 서로 다른 시점에서 유효성 검사 수행(내장된 epoch당 유효성 검사에서 더욱 확장)\n",
    "- 정기적으로 또는 특정 정확도 임계값을 초과할 때 모델 검사점 설정\n",
    "- 훈련이 평탄해진 것으로 보일 때 모델의 학습률 변경\n",
    "- 훈련이 평탄해진 것으로 보일 때 최상위 레이어의 미세 조정 수행\n",
    "- 훈련이 종료되거나 특정 성능 임계값이 초과된 경우 이메일 또는 인스턴트 메시지로 알림 보내기\n",
    "- 기타\n",
    "\n",
    "콜백은 `fit()`에 대한 호출에 목록으로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1b12038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:02.438916Z",
     "iopub.status.busy": "2022-12-14T23:01:02.438664Z",
     "iopub.status.idle": "2022-12-14T23:01:13.113942Z",
     "shell.execute_reply": "2022-12-14T23:01:13.113301Z"
    },
    "id": "15036ddbee42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3713 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.2268 - val_sparse_categorical_accuracy: 0.9335\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1698 - sparse_categorical_accuracy: 0.9496 - val_loss: 0.1686 - val_sparse_categorical_accuracy: 0.9506\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.1439 - val_sparse_categorical_accuracy: 0.9579\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.0962 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.1499 - val_sparse_categorical_accuracy: 0.9558\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9758 - val_loss: 0.1354 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177a2c5d700>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fccd5",
   "metadata": {
    "id": "15f5af3b6da9"
   },
   "source": [
    "### 많은 내장 콜백을 사용할 수 있습니다\n",
    "\n",
    "Keras에서 이미 사용할 수 있는 내장 콜백은 다음과 같습니다.\n",
    "\n",
    "- `ModelCheckpoint`: 주기적으로 모델을 저장\n",
    "- `EarlyStopping`: 훈련이 더 이상 유효성 검사 메트릭을 개선하지 못하는 경우 훈련을 중단\n",
    "- `TensorBoard`:  시각화할 수 있는 모델 로그를 정기적으로 작성\n",
    "- `CSVLogger`: 손실 및 메트릭 데이터를 CSV 파일로 스트리밍\n",
    "- 기타\n",
    "\n",
    "\n",
    "### 고유한 콜백 작성하기\n",
    "\n",
    "`self.model`을 통해 연관된 모델에 액세스 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "908f1fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:13.117425Z",
     "iopub.status.busy": "2022-12-14T23:01:13.116918Z",
     "iopub.status.idle": "2022-12-14T23:01:13.120887Z",
     "shell.execute_reply": "2022-12-14T23:01:13.120314Z"
    },
    "id": "b265d36ce608"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e44245",
   "metadata": {
    "id": "5ee672524987"
   },
   "source": [
    "## 모델 검사점 설정하기\n",
    "\n",
    "상대적으로 큰 데이터세트에 대한 모델을 훈련시킬 때는 모델의 검사점을 빈번하게 저장하는 것이 중요\n",
    "\n",
    "이를 수행하는 가장 쉬운 방법은 `ModelCheckpoint` 콜백을 사용하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e453d8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:13.124394Z",
     "iopub.status.busy": "2022-12-14T23:01:13.123835Z",
     "iopub.status.idle": "2022-12-14T23:01:18.417117Z",
     "shell.execute_reply": "2022-12-14T23:01:18.416502Z"
    },
    "id": "83614be57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "601/625 [===========================>..] - ETA: 0s - loss: 0.3956 - sparse_categorical_accuracy: 0.8907\n",
      "Epoch 1: val_loss improved from inf to 0.27124, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3899 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.2712 - val_sparse_categorical_accuracy: 0.9176\n",
      "Epoch 2/2\n",
      "616/625 [============================>.] - ETA: 0s - loss: 0.1852 - sparse_categorical_accuracy: 0.9455\n",
      "Epoch 2: val_loss improved from 0.27124 to 0.18012, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1855 - sparse_categorical_accuracy: 0.9454 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x177bd3c9f40>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d1486",
   "metadata": {
    "id": "7f6afa36950c"
   },
   "source": [
    "`ModelCheckpoint` 콜백을 사용하여 내결함성을 구현할 수 있습니다. 즉, 훈련이 무작위로 중단되는 경우 모델의 마지막 저장된 상태에서 훈련을 다시 시작할 수 있습니다. 다음은 기본적인 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cebf9d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:18.420696Z",
     "iopub.status.busy": "2022-12-14T23:01:18.420209Z",
     "iopub.status.idle": "2022-12-14T23:01:29.612314Z",
     "shell.execute_reply": "2022-12-14T23:01:29.611605Z"
    },
    "id": "27ce92b2ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "  82/1563 [>.............................] - ETA: 2s - loss: 1.1295 - sparse_categorical_accuracy: 0.7092 INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=1.02\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=1.02\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 186/1563 [==>...........................] - ETA: 6s - loss: 0.7449 - sparse_categorical_accuracy: 0.8009INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.72\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.72\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 295/1563 [====>.........................] - ETA: 6s - loss: 0.6025 - sparse_categorical_accuracy: 0.8362INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.60\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.60\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 384/1563 [======>.......................] - ETA: 6s - loss: 0.5419 - sparse_categorical_accuracy: 0.8510INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.53\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.53\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 496/1563 [========>.....................] - ETA: 6s - loss: 0.4890 - sparse_categorical_accuracy: 0.8635INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.49\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.49\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 598/1563 [==========>...................] - ETA: 5s - loss: 0.4547 - sparse_categorical_accuracy: 0.8721INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.45\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.45\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 687/1563 [============>.................] - ETA: 5s - loss: 0.4302 - sparse_categorical_accuracy: 0.8784INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.43\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.43\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 784/1563 [==============>...............] - ETA: 4s - loss: 0.4087 - sparse_categorical_accuracy: 0.8838INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.41\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.41\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 875/1563 [===============>..............] - ETA: 4s - loss: 0.3908 - sparse_categorical_accuracy: 0.8887INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.39\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.39\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 998/1563 [==================>...........] - ETA: 3s - loss: 0.3718 - sparse_categorical_accuracy: 0.8936INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.37\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.37\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1091/1563 [===================>..........] - ETA: 3s - loss: 0.3571 - sparse_categorical_accuracy: 0.8974INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.36\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.36\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185/1563 [=====================>........] - ETA: 2s - loss: 0.3455 - sparse_categorical_accuracy: 0.9002INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.34\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.34\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286/1563 [=======================>......] - ETA: 1s - loss: 0.3345 - sparse_categorical_accuracy: 0.9028INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378/1563 [=========================>....] - ETA: 1s - loss: 0.3266 - sparse_categorical_accuracy: 0.9048INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483/1563 [===========================>..] - ETA: 0s - loss: 0.3176 - sparse_categorical_accuracy: 0.9077INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3118 - sparse_categorical_accuracy: 0.9093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779d7081c0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83741eea",
   "metadata": {
    "id": "da3ab58d5235"
   },
   "source": [
    "모델 저장 및 복원을 위한 자체 콜백을 작성할 수도 있습니다.\n",
    "\n",
    "직렬화 및 저장에 대한 자세한 설명은 [모델 저장 및 직렬화 가이드](https://www.tensorflow.org/guide/keras/save_and_serialize/)를 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077cc9d",
   "metadata": {
    "id": "b9342cc2ddba"
   },
   "source": [
    "## 학습률 일정 사용하기\n",
    "\n",
    "딥 러닝 모델을 훈련할 때 일반적인 패턴은 훈련이 진행됨에 따라 점차적으로 학습을 줄이는 것입니다. 이것을 일반적으로 \"학습률 감소\"라고 합니다.\n",
    "\n",
    "학습 감소 일정은 정적(현재 epoch 또는 현재 배치 인덱스의 함수로 미리 고정됨) 또는 동적(모델의 현재 동작, 특히 유효성 검사 손실에 대응)일 수 있습니다.\n",
    "\n",
    "### 최적화 프로그램으로 일정 전달하기\n",
    "\n",
    "최적화 프로그램에서 schedule 객체를 `learning_rate` 인수로 전달하여 정적 학습률 감소 일정을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d51d809d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:29.616151Z",
     "iopub.status.busy": "2022-12-14T23:01:29.615603Z",
     "iopub.status.idle": "2022-12-14T23:01:29.627912Z",
     "shell.execute_reply": "2022-12-14T23:01:29.627258Z"
    },
    "id": "684f0ab6d3de"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8caf80",
   "metadata": {
    "id": "03b61ddd9586"
   },
   "source": [
    "`ExponentialDecay` , `PiecewiseConstantDecay` , `PolynomialDecay` 및 `InverseTimeDecay`와 같은 몇 가지 내장된 일정을 사용할 수 있습니다.\n",
    "\n",
    "### 콜백을 사용하여 동적 학습률 일정 구현하기\n",
    "\n",
    "최적화 프로그램이 유효성 검사 메트릭에 액세스할 수 없으므로 이러한 일정 객체로는 동적 학습률 일정(예: 유효성 검사 손실이 더 이상 개선되지 않을 때 학습률 감소)을 달성할 수 없습니다.\n",
    "\n",
    "그러나 콜백은 유효성 검사 메트릭을 포함해 모든 메트릭에 액세스할 수 있습니다! 따라서 최적화 프로그램에서 현재 학습률을 수정하는 콜백을 사용하여 이 패턴을 달성할 수 있습니다. 실제로 이 부분이`ReduceLROnPlateau` 콜백으로 내장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b4c3e",
   "metadata": {
    "id": "7f8b9539cd57"
   },
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기\n",
    "\n",
    "훈련 중에 모델을 주시하는 가장 좋은 방법은 로컬에서 실행할 수 있는 브라우저 기반 애플리케이션인 [TensorBoard](https://www.tensorflow.org/tensorboard)를 사용하는 것입니다. 이 보드에는 다음과 같은 정보가 제공됩니다.\n",
    "\n",
    "- 훈련 및 평가를 위한 손실 및 메트릭을 실시간으로 플롯\n",
    "- (옵션) 레이어 활성화 히스토그램 시각화\n",
    "- (옵션) `Embedding` 레이어에서 학습한 포함된 공간의 3D 시각화\n",
    "\n",
    "pip와 함께 TensorFlow를 설치한 경우, 명령줄에서 TensorBoard를 시작할 수 있습니다.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f393be3e",
   "metadata": {
    "id": "f2685d7ce531"
   },
   "source": [
    "### TensorBoard 콜백 사용하기\n",
    "\n",
    "TensorBoard를 Keras 모델 및 `fit()` 메서드와 함께 사용하는 가장 쉬운 방법은 `TensorBoard` 콜백입니다.\n",
    "\n",
    "가장 간단한 경우로, 콜백에서 로그를 작성할 위치만 지정하면 바로 로그를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "452dcaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T23:01:29.631614Z",
     "iopub.status.busy": "2022-12-14T23:01:29.631009Z",
     "iopub.status.idle": "2022-12-14T23:01:29.636000Z",
     "shell.execute_reply": "2022-12-14T23:01:29.635384Z"
    },
    "id": "f74247282ff6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.TensorBoard at 0x177b24fe340>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1513f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "til"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
