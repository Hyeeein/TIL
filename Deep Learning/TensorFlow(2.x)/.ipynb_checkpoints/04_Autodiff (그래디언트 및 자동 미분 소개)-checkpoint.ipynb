{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47ba641",
   "metadata": {},
   "source": [
    "## 자동 미분 및 그래디언트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff24d59",
   "metadata": {},
   "source": [
    "* 자동 미분: 역전파 알고리즘과 같은 머신러닝 알고리즘 구현에 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237015d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e3d882",
   "metadata": {},
   "source": [
    "## 그래디언트 계산하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ba232",
   "metadata": {},
   "source": [
    "자동으로 미분하기 위해 Tensorflow는 정방향 패스동안 어떤 연산이 어떤 순서로 발생했는지 기억해야 함\n",
    "\n",
    "그리고 역방향 패스동안 Tensorflow는 이 연산 목록을 역순으로 이동하여 그래디언트 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa352e4",
   "metadata": {},
   "source": [
    "## 그래디언트 테이프"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed948a7b",
   "metadata": {},
   "source": [
    "* tf.GradientTape API : 자동 미분을 위한 API 제공\n",
    "\n",
    "\n",
    "* `tf.GradientTape`\n",
    "    - 컨텍스트(context) 안에서 실행된 모든 연산을 테이프(tape)에 기록\n",
    "    - 후진 방식 자동 미분(reverse mode differentitation)을 사용해 테이프에 기록된 연산의 그래디언트 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467ba3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547609b",
   "metadata": {},
   "source": [
    "`GradientTape.gradient(target, sources)`\n",
    "\n",
    "- 일부 소스(종종 모델 변수)에 상대적인 일부 대상(종종 손실)의 그래디언트를 계산\n",
    "- 모든 텐서에서 쉽게 작동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23aa14bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9d2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y = x @ w + b\n",
    "    loss = tf.reduce_mean(y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab45f90",
   "metadata": {},
   "source": [
    "두 변수 모두에게 loss의 그래디언트를 가져오려면, 두 변수를 gradient 메서드에 소스로 전달 가능\n",
    "\n",
    "테이프는 소스가 전달되는 방식에 대해 융통성이 있으며, 목록 또는 사전의 중첩된 조합을 허용하고 같은 방식으로 구조화된 그래디언트를 반환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4578b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698fe85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 각 소스에 대한 그래디언트는 소스의 형상을 가짐\n",
    "print(w.shape)\n",
    "print(dl_dw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1ef48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-4.2609806,  2.4636304], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래디언트 계산: 변수의 사전을 전달\n",
    "my_vars = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}\n",
    "\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "grad['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec78dd",
   "metadata": {},
   "source": [
    "## 모델에 대한 그래디언트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7e05c",
   "metadata": {},
   "source": [
    "`tf.Module`\n",
    "\n",
    "- 검사점 설정 및 내보내기를 위해 `tf.Variable`을 수집\n",
    "- 모든 서브 클래스는 `Module.trainable_variables` 속성에서 변수를 집계, 몇 줄의 코드로 그래디언트 계산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4765729",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Forward pass\n",
    "    y = layer(x)\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "\n",
    "# Calculate gradients with respect to every trainable variable\n",
    "grad = tape.gradient(loss, layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c5e91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense/kernel:0, shape: (3, 2)\n",
      "dense/bias:0, shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "    print(f'{var.name}, shape: {g.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ab41a",
   "metadata": {},
   "source": [
    "## 테이프의 감시 대상 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f640b96",
   "metadata": {},
   "source": [
    "기본 동작은 훈련 가능한 `tf.Variable`에 엑세스한 후, 모든 연산을 기록하는 것\n",
    "\n",
    "왜 기록해야 할까?\n",
    "\n",
    "- 테이프는 역방향 패스의 그래디언트를 계산하기 위해 정방향 패스 기록할 연산을 알아야 함\n",
    "- 테이프는 중간에 대한 참조를 보유하므로 불필요한 연산을 기록하지 않음\n",
    "- 가장 일반적인 예: 모든 모델의 훈련 가능 가능한 변수에 대해 손실 그래디언트를 계산하는 것\n",
    "\n",
    "##### (예) tf.Tensor가 기본적으로 감시되지 않고, tf.Variable을 훈련할 수 없어 그래디언트 계산 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80caea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33563b2",
   "metadata": {},
   "source": [
    "`GradientTape.watched_variables` : 메서드를 사용하여 테이프에서 감시중인 변수 나열 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc31540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258454f",
   "metadata": {},
   "source": [
    "`tf.GradientTape` : 사용자가 감시 대상 또는 감시 예외 대상 제어할 수 있는 후크 제공\n",
    "\n",
    "`GradientTape.watch(x)` : tf.Tensor에 대한 그래디언트 기록을 위해 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2166ca42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc48313",
   "metadata": {},
   "source": [
    "`watch_accessed_variables=False`: 모든 `tf.Variables`을 감시하는 기본 동작 비활성화 하기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a586d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.Variable(0.0)\n",
    "x1 = tf.Variable(10.0)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    tape.watch(x1)\n",
    "    y0 = tf.math.sin(x0)\n",
    "    y1 = tf.nn.softplus(x1)\n",
    "    y = y0 + y1\n",
    "    ys = tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8f256",
   "metadata": {},
   "source": [
    "x0에서 `GradientTape.watch`가 호출되지 않았으므로, 그래디언트가 계산되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11dbbca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx0: None\n",
      "dy/dx1: 0.9999546\n"
     ]
    }
   ],
   "source": [
    "# dys/dx1 = exp(x1) / (1 + exp(x1)) = sigmoid(x1)\n",
    "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
    "\n",
    "print('dy/dx0:', grad['x0'])\n",
    "print('dy/dx1:', grad['x1'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9fc5a",
   "metadata": {},
   "source": [
    "## 중간 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6262d",
   "metadata": {},
   "source": [
    "`tf.GradientTape` : 컨텍스트 내에서 계산된 중간값과 관련하여, 출력의 그래디언트 요청할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ee6eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x\n",
    "    z = y * y\n",
    "\n",
    "# Use the tape to compute the gradient of z with respect to the\n",
    "# intermediate value y.\n",
    "# dz_dy = 2 * y and y = x ** 2 = 9\n",
    "print(tape.gradient(z, y).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be32527",
   "metadata": {},
   "source": [
    "`GradientTape.gradient` 메서드 호출 -> GradientTape가 보유한 리소스 해제\n",
    "\n",
    "동일한 계산에 대해 여러 그래디언트를 계산하려면 `persistent=True` 그래디언트 테이프를 만듦 <br>\n",
    "그러면, 리소스 해제될 때 gradient 메서드 여러 번 호출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73f90d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4. 108.]\n",
      "[2. 6.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 3.0])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    y = x * x\n",
    "    z = y * y\n",
    "\n",
    "print(tape.gradient(z, x).numpy())  # [4.0, 108.0] (4 * x**3 at x = [1.0, 3.0])\n",
    "print(tape.gradient(y, x).numpy())  # [2.0, 6.0] (2 * x at x = [1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11b3fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tape   # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99dea05",
   "metadata": {},
   "source": [
    "## 성능에 대한 참고 사항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f6834c",
   "metadata": {},
   "source": [
    "- 그래디언트 테이프 컨텍스트 내 연산 수행 : 작은 오버헤드 존재 -> 필요한 경우만 사용\n",
    "\n",
    "\n",
    "- 그래디언트 테이프는 메모리를 사용하여 역방향 패스동안 사용하기 위해 입출력을 포함한 중간 결과까지 저장\n",
    "    - 효율성을 위해(ReLU와 같은) 일부 연산은 중간 결과를 유지할 필요가 없으며 정방향 패스 동안 정리\n",
    "    - But, `persistent=True`를 사용하면, 아무것도 삭제되지 않아 최대 메모리 사용량 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad63bd1",
   "metadata": {},
   "source": [
    "## 스칼라가 아닌 대상의 그래디언트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb688f",
   "metadata": {},
   "source": [
    "그래디언트는 기본적으로 스칼라에 대한 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6019b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "-0.25\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y0 = x**2\n",
    "    y1 = 1 / x\n",
    "\n",
    "print(tape.gradient(y0, x).numpy())\n",
    "print(tape.gradient(y1, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde026b",
   "metadata": {},
   "source": [
    "따라서, 여러 대상의 그래디언트 요청 시 각 소스의 결과는 다음과 같음 \n",
    "\n",
    "- 대상의 합계 또는 그에 상응하는 그래디언트\n",
    "- 각 대상의 그래디언트의 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40e9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    y0 = x**2\n",
    "    y1 = 1 / x\n",
    "\n",
    "print(tape.gradient({'y0': y0, 'y1': y1}, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad036a",
   "metadata": {},
   "source": [
    "대상이 스칼라가 아닌 경우, 합계의 그래디언트로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd03d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * [3., 4.]\n",
    "\n",
    "print(tape.gradient(y, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70cc0a6",
   "metadata": {},
   "source": [
    "이렇게 하면, 손실 컬렉션 합계의 그래디언트 또는 요소별 손실 계산 합계의 그래디언트를 간단하게 구현할 수 있음\n",
    "\n",
    "- 각 항목에 대해 별도의 그래디언트가 필요한 경우, 야고비안 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b20a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 200+1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.nn.sigmoid(x)\n",
    "\n",
    "dy_dx = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e5fe0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, label='y')\n",
    "plt.plot(x, dy_dx, label='dy/dx')\n",
    "plt.legend()\n",
    "_ = plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557da38",
   "metadata": {},
   "source": [
    "## 흐름 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a2cf1",
   "metadata": {},
   "source": [
    "그래디언트 테이프 : 실해오디는 연산을 기록하므로, Python 제어 흐름이 자연스럽게 처리됨\n",
    "\n",
    "여기서는 if의 각 분기에 서로 다른 변수가 사용됨. 그래디언트는 사용된 변수에만 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71991c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(1.0)\n",
    "\n",
    "v0 = tf.Variable(2.0)\n",
    "v1 = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    if x > 0.0:\n",
    "        result = v0\n",
    "    else:\n",
    "        result = v1**2 \n",
    "\n",
    "dv0, dv1 = tape.gradient(result, [v0, v1])\n",
    "\n",
    "print(dv0)\n",
    "print(dv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36fde3",
   "metadata": {},
   "source": [
    "제어문 자체는 미분할 수 없으므로, 그래디언트 기반 최적화 프로그램에는 보이지 않음\n",
    "\n",
    "위 예제에서 x 값에 따라 테이프는 result = v0 또는 result = v1**2를 기록 <br>\n",
    "x에 대한 그래디언트는 항상 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7635392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "dx = tape.gradient(result, x)\n",
    "\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4d941",
   "metadata": {},
   "source": [
    "## gradient가 None을 반환하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7d277",
   "metadata": {},
   "source": [
    "대상이 소스와 연결되어 있지 않으면 gradient가 None을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e65077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = y * y\n",
    "print(tape.gradient(z, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8762e2f",
   "metadata": {},
   "source": [
    "### 그래디언트의 연결을 끊을 수 있는 몇 가지 덜 명확한 방법 4가지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e23508",
   "metadata": {},
   "source": [
    "### 1. 변수가 텐서로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2bde62",
   "metadata": {},
   "source": [
    "한 가지 일반적인 오류: `Variable.assign`을 사용하여 `tf.Variable`을 업데이트하는 대신, <br>\n",
    "실수로 `tf.Variable`을 `tf.Tensor`로 대체하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77504ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "EagerTensor : None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "for epoch in range(2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = x+1\n",
    "\n",
    "    print(type(x).__name__, \":\", tape.gradient(y, x))\n",
    "    x = x + 1   # This should be `x.assign_add(1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a854a97",
   "metadata": {},
   "source": [
    "### 2. TensorFlow 외부에서 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089012c",
   "metadata": {},
   "source": [
    "계산에서 TensorFlow를 종료하면 테이프가 그래디언트 경로 기록 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22d2af74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.0, 2.0],\n",
    "                 [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    x2 = x**2\n",
    "\n",
    "    # This step is calculated with NumPy\n",
    "    y = np.mean(x2, axis=0)\n",
    "\n",
    "    # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n",
    "    # using `tf.convert_to_tensor`.\n",
    "    y = tf.reduce_mean(y, axis=0)\n",
    "\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae80a4f",
   "metadata": {},
   "source": [
    "### 3. 정수 또는 문자열을 통해 그래디언트를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d67804",
   "metadata": {},
   "source": [
    "정수와 문자열은 구별할 수 없음. dtype을 지정하지 않으면, 실수로 int 상수 또는 변수를 만들기 쉬움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e00db80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = x * x\n",
    "\n",
    "print(g.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120242a",
   "metadata": {},
   "source": [
    "TensorFlow는 유형 간에 자동으로 전송되지 않으므로, 실제로 그래디언트가 누락되는 대신 유형 오류 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350140bf",
   "metadata": {},
   "source": [
    "### 4. 상태 저장 개체를 통해 그래디언트를 구함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c3206",
   "metadata": {},
   "source": [
    "상태가 그래디언트를 중지함. 상태 저장 객체에서 읽을 때, 테이프는 현재 상태만 볼 수 있음 (기록 X)\n",
    "\n",
    "`tf.Tensor`는 변경할 수 없음. 텐서가 작성된 후에는 변경할 수 없음. 값은 있지만 상태는 X. 지금까지 논의된 모든 연산은 상태 비저장\n",
    "\n",
    "`tf.matmul`의 출력은 입력에만 의존\n",
    "\n",
    "`tf.Variable`은 내부 상태와 값을 가짐. 변수를 사용하면 상태를 읽음. 변수와 관련하여 그래디언트를 계산하는 것이 일반적이지만, 변수의 상태는 그래디언트 계산이 더 멀리 돌아가지 않도록 차단함\n",
    "\n",
    "`tf.data.Dataset` 반복기(iterator)와 `tf.queue`는 상태 저장이며, 이들을 통과하는 텐서의 모든 그래디언트를 중지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbc3a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x0 = tf.Variable(3.0)\n",
    "x1 = tf.Variable(0.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Update x1 = x1 + x0.\n",
    "    x1.assign_add(x0)\n",
    "    # The tape starts recording from x1.\n",
    "    y = x1**2   # y = (x1 + x0)**2\n",
    "\n",
    "# This doesn't work.\n",
    "print(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86b0bd",
   "metadata": {},
   "source": [
    "## 그래디언트가 등록되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05733f0",
   "metadata": {},
   "source": [
    "`tf.Operation`: 미분 불가능한 것으로 등록되어 None 을 반환, 다른 연산엔 그래디언트 등록 안됨\n",
    "\n",
    "`tf.raw_ops` : 그래디언트가 등록된 저수준 op가 표시\n",
    "\n",
    "그래디언트가 등록되지 않은 float op를 통해, 그래디언트를 얻고자 시도하면 테이프가 자동으로 None을 반환하는 대신 오류가 발생\n",
    "\n",
    "예를 들어, `tf.image.adjust_contrast` 함수는 그래디언트를 가질 수 있지만, 그래디언트는 구현되지 않은 `raw_ops.AdjustContrastv2`를 래핑함\n",
    "\n",
    "이 op를 미분해야 하는 경우, `tf.RegisterGradient`를 사용하여 그래디언트를 구현하고, 등록하거나 다른 ops를 사용하여 함수를 다시 구현해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac605160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupError: gradient registry has no entry for: AdjustContrastv2\n"
     ]
    }
   ],
   "source": [
    "image = tf.Variable([[[0.5, 0.0, 0.0]]])\n",
    "delta = tf.Variable(0.1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    new_image = tf.image.adjust_contrast(image, delta)\n",
    "\n",
    "try:\n",
    "    print(tape.gradient(new_image, [image, delta]))\n",
    "    assert False   # This should not happen.\n",
    "except LookupError as e:\n",
    "    print(f'{type(e).__name__}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f78a51",
   "metadata": {},
   "source": [
    "## None 대신 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49dfa0",
   "metadata": {},
   "source": [
    "연결되지 않은 그래디언트의 경우, None 대신 0을 가져오는 것이 편리한 경우가 있음\n",
    "\n",
    "연결되지 않은 그래디언트가 있을 때, `unconnected_gradients` 인수를 사용하여 반환할 항목 결정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5f16376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2., 2.])\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = y**2\n",
    "print(tape.gradient(z, x, unconnected_gradients=tf.UnconnectedGradients.ZERO))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "til"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
