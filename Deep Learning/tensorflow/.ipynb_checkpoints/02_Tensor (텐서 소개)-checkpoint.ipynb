{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894ea698",
   "metadata": {},
   "source": [
    "## 텐서\n",
    "\n",
    "\n",
    "* 텐서 : 일관된 유형(`dtype`)을 가진 다차원 배열\n",
    "    - `tf.dtypes.DType` : 지원되는 모든 `dtype` 확인 가능\n",
    "    - Numpy 의 `np.arrays`와 유사\n",
    "\n",
    "\n",
    "* 모든 텐서는 Python 숫자 및 문자열과 같이 변경할 수 없음\n",
    "* 텐서의 내용을 업데이트 할 수 없으며, 새로운 텐서를 만들 수만 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64042fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036990e5",
   "metadata": {},
   "source": [
    "## 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2188679",
   "metadata": {},
   "source": [
    "기본 텐서 생성\n",
    "\n",
    "1. 스칼라 또는 순위-0 텐서 생성 (스칼라는 축이 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e109ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c4eab",
   "metadata": {},
   "source": [
    "2. 벡터 또는 순위-1 텐서 생성 (벡터에는 하나의 축이 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a8def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Let's make this a float tensor.\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb7c6e",
   "metadata": {},
   "source": [
    "3. 행렬 또는 순위-2 텐서에는 두 개의 축이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd2f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]], shape=(3, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# If you want to be specific, you can set the dtype (see below) at creation time\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641f57d",
   "metadata": {},
   "source": [
    "4. 텐서에는 더 많은 축이 있을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d928ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# There can be an arbitrary number of\n",
    "# axes (sometimes called \"dimensions\")\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd1a3f",
   "metadata": {},
   "source": [
    "`np.array`, `tensor.numpy` 메서드를 사용하여 텐서를 NumPy 배열로 변환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f21986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b27ac70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.]], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c77b05",
   "metadata": {},
   "source": [
    "### 텐서의 유형\n",
    "\n",
    "- 보통 float, int가 포함되지만, *복소수, 문자열*과 같은 유형이 있음\n",
    "- 기본 `tf.Tensor` 클래스에는 텐서가 직사각형이어야 함. 즉, 각 축을 따라 모든 요소의 크기가 같음. 그러나, 다양한 형상을 처리할 수 있는 특수 유형의 텐서가 존재\n",
    "    - 비정형 텐서\n",
    "    - 희소 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554239f0",
   "metadata": {},
   "source": [
    "### 텐서 연산\n",
    "\n",
    "- 덧셈, 요소별 곱셈 및 행렬 곱셈을 포함하여 텐서에 대한 기본 산술 수행 가능\n",
    "- 모든 종류의 연산(ops)에 텐서를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ebc2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d9d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e6f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(c))\n",
    "# Find the index of the largest value\n",
    "print(tf.math.argmax(c))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51552fc3",
   "metadata": {},
   "source": [
    "[참고]\n",
    "\n",
    "일반적으로 TensorFlow 함수가 `Tensor`를 입력 받을 것으로 예상하는 경우, <br>\n",
    "이 함수는 `tf.convert_to_tensor`를 사용하여 `Tensor`로 변환할 수 있는 모든 항목을 허용하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314c6949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e2d0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce671bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec0ffe",
   "metadata": {},
   "source": [
    "## 형상 정보\n",
    "\n",
    "\n",
    "* 형상 : 텐서의 각 차원의 길이 (요소의 수)\n",
    "* 순위 : 텐서 축의 수. 스칼라는 순위가 0, 벡터의 순위는 1, 행렬의 순위는 2\n",
    "* 축 또는 차원 : 텐서의 특정 차원\n",
    "* 크기 : 텐서의 총 항목 수, 형상 벡터 요소의 곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4830b",
   "metadata": {},
   "source": [
    "텐서 및 `tf.TensorShape` 객체에는 다음에 엑세스하기 위한 편리한 속성 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7113794",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d780fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of axes: 4\n",
      "Shape of tensor: (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 3\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5):  120\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
    "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14278564",
   "metadata": {},
   "source": [
    "`Tensor.ndim`, `Tensor.shape` : Tensor 객체를 반환하지 않음\n",
    "\n",
    "Tensor 객체가필요한 경우, `tf.rank` 또는 `tf.shape` 함수를 사용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ddfb030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06abb5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 4, 5])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e9bc3",
   "metadata": {},
   "source": [
    "축은 종종 인덱스를 참조하지만, 항상 각 축의 의미를 추적해야 함\n",
    "\n",
    "축이 전역에서 로컬로 정렬되는 경우가 종종 있음\n",
    "\n",
    "배치 축이 먼저 오고, 그 다음에 공간 차원과 각 위치의 특성이 마지막에 옴\n",
    "\n",
    "이러한 특성 벡터는 연속적인 메모리 영역 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba0daf",
   "metadata": {},
   "source": [
    "## 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb424fc",
   "metadata": {},
   "source": [
    "### 단일 축 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf2a04",
   "metadata": {},
   "source": [
    "* TensorFlow는 표준 Python 인덱싱 규칙과 NumPy 인덱싱 기본 규칙을 따름\n",
    "\n",
    "1. 인덱스는 0에서 시작\n",
    "2. 음수 인덱스는 끝에서부터 거꾸로 계산\n",
    "3. 콜론, :은 start:stop:step 슬라이스에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f664b69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  2  3  5  8 13 21 34]\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "print(rank_1_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23170e2",
   "metadata": {},
   "source": [
    "* 스칼라를 사용하여 인덱싱하면 축이 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "462fc581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 0\n",
      "Second: 1\n",
      "Last: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040131d5",
   "metadata": {},
   "source": [
    "* : 슬라이스를 사용하여 인덱싱하면 축이 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ab189a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
      "Before 4: [0 1 1 2]\n",
      "From 4 to the end: [ 3  5  8 13 21 34]\n",
      "From 2, before 7: [1 2 3 5 8]\n",
      "Every other item: [ 0  1  3  8 21]\n",
      "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19e83d",
   "metadata": {},
   "source": [
    "### 다축 인덱싱\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c162ba2",
   "metadata": {},
   "source": [
    "* 더 높은 순위의 텐서는 여러 인덱스를 전달하여 인덱싱 됨\n",
    "* 단일 축의 경우에서와 정확히 같은 규칙이 각 축에 독립적으로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f990c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "print(rank_2_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118fba3",
   "metadata": {},
   "source": [
    "* 각 인덱스에 정수를 전달하면 결과는 스칼라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cbaa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Pull out a single value from a 2-rank tensor\n",
    "print(rank_2_tensor[1, 1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003152b",
   "metadata": {},
   "source": [
    "* 정수와 슬라이스의 조합을 사용하여 인덱싱할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f825f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get row and column tensors\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aab4e6",
   "metadata": {},
   "source": [
    "##### (예) 3축 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa87a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4  9]\n",
      " [14 19]\n",
      " [24 29]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor[:, :, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bef2e",
   "metadata": {},
   "source": [
    "텐서 슬라이싱 가이드 : https://www.tensorflow.org/guide/tensor_slicing?hl=ko&_gl=1*1svdizu*_ga*MTU3ODM2MjQxMC4xNjgwMTYyMDU0*_ga_W0YLR4190T*MTY4MDIzOTYxMi41LjEuMTY4MDI0NDY4OC4wLjAuMA.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a842f9",
   "metadata": {},
   "source": [
    "## 형상 조작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34b89d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape returns a `TensorShape` object that shows the size along each axis\n",
    "x = tf.constant([[1], [2], [3]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c191f177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "# You can convert this object into a Python list, too\n",
    "print(x.shape.as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ab355",
   "metadata": {},
   "source": [
    "* `tf.reshape`: 텐서를 새로운 형상으로 바꿀 수 있음\n",
    "\n",
    "    - 데이터의 레이아웃은 메모리에 유지되고, 요청된 형상이 같은 데이터를 가리키는 새 텐서 작성\n",
    "    - '행 중심' 메모리 순서를 사용하므로, 가장 오른쪽 인덱스 증가시키면 단일 단계에 해당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "229e9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reshape a tensor to a new shape.\n",
    "# Note that you're passing in a list\n",
    "reshaped = tf.reshape(x, [1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "803e43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f013cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a715d",
   "metadata": {},
   "source": [
    "* 텐서를 평평하게 하면 어떤 순서로 메모리에 배치되어 있는지 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8470ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
    "print(tf.reshape(rank_3_tensor, [-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318eea9f",
   "metadata": {},
   "source": [
    "* `tf.reshape`의 합리적인 용도\n",
    "    - 인접한 축을 결합하거나 분할하는 것뿐 (1을 추가 또는 제거)\n",
    "    - 3 x 2 x 5 텐서의 경우, 슬라이스가 혼합되지 않으므로, (3 x 2) x 5 또는 3 x (2 x 5)로 재구성하는 것이 합리적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab2b49cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c5d23",
   "metadata": {},
   "source": [
    "* `tf.transpose` : `tf.reshape`에서 축 교환이 작동하지 않으면 수행\n",
    "    - 완전히 지정되지 않은 형상 전체에 걸쳐 실행할 수 있음\n",
    "    - 형상에 None(축 길이를 알 수 없음)이 포함되거나 전체 형상이 None(텐서의 순위를 알 수 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb16b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
      "\n",
      "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
     ]
    }
   ],
   "source": [
    "# Bad examples: don't do this\n",
    "\n",
    "# You can't reorder axes with reshape.\n",
    "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
    "\n",
    "# This is a mess\n",
    "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
    "\n",
    "# This doesn't work at all\n",
    "try:\n",
    "  tf.reshape(rank_3_tensor, [7, -1])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2238ed9",
   "metadata": {},
   "source": [
    "`tf.RaggedTensor`를 제외하고, 이러한 형상은 TensorFlow의 상징적인 그래프 빌딩 API 컨텍스트에서만 발생\n",
    "\n",
    "* tf.function\n",
    "* keras 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f3567",
   "metadata": {},
   "source": [
    "## DTypes에 대한 추가 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9bbcc",
   "metadata": {},
   "source": [
    "* `Tensor.dtype` : `tf.Tensor`의 데이터 유형 검사 시 사용\n",
    "\n",
    "\n",
    "* 보통 `tf.Tensor`를 만들 때, 선택적으로 데이터 유형을 지정할 수 있음\n",
    "    - 지정하지 않을 경우, TensorFlow는 데이터를 나타낼 수 있는 데이터 유형을 선택\n",
    "    - `tf.int32` : Python 정수\n",
    "    - `tf.float32` : 파이썬 부동 소수점 숫자\n",
    "    \n",
    "    \n",
    "* 유형별로 캐스팅할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0985532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
    "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
    "\n",
    "# Now, cast to an uint8 and lose the decimal precision\n",
    "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
    "print(the_u8_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece79c26",
   "metadata": {},
   "source": [
    "## 브로드캐스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73616599",
   "metadata": {},
   "source": [
    "* 특정 조건에서 작은 텐서는 결합된 연산을 실행할 때, 더 큰 텐서에 맞게 자동으로 확장됨\n",
    "\n",
    "##### (예) 스칼라에 텐서를 곱하거나 추가하려고 할 때, 스칼라는 다른 인수와 같은 형상으로 브로드캐스트 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5619dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "# All of these are the same computation\n",
    "print(tf.multiply(x, 2))\n",
    "print(x * y)\n",
    "print(x * z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec34f9",
   "metadata": {},
   "source": [
    "* 크기가 1인 축은 다른 인수와 일치하도록 확장할 수 있음. 두 인수 모두 같은 계산을 확장 가능\n",
    "* 이 경우, 3 x 1 행렬에 요소별로 1 x 4 행렬을 곱하여 3 x 4 행렬을 만듦. 선행이 1인 선택 사항인 점에 유의. y의 형상은 [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3a1d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# These are the same computations\n",
    "x = tf.reshape(x,[3,1])\n",
    "y = tf.range(1, 5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb67dd",
   "metadata": {},
   "source": [
    "##### (예) 브로드캐스팅이 없는 같은 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "335c282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_stretch = tf.constant([[1, 1, 1, 1],\n",
    "                         [2, 2, 2, 2],\n",
    "                         [3, 3, 3, 3]])\n",
    "\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "print(x_stretch * y_stretch)  # Again, operator overloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819a5a1",
   "metadata": {},
   "source": [
    "대부분의 경우, 브로드캐스팅은 브로드캐스트 연산으로 메모리에서 확장된 텐서를 구체화 안함<br>\n",
    "따라서, 시간적 공간적으로도 효율적임\n",
    "\n",
    "* `tf.broadcast_to` : 브로드캐스팅이 어떤 모습인지 알 수 있음\n",
    "    - 수학적 op와 달리, 메모리를 절약하기 위해 특별한 연산을 수행하지 않음\n",
    "    - 여기에서 텐서를 구체화 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79c165c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0f31f",
   "metadata": {},
   "source": [
    "## tf.convert_to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdd87d",
   "metadata": {},
   "source": [
    "`tf.matmul` 및 `tf.reshape`와 같은 대부분의 ops는 클래스 `tf.Tensor`의 인수를 사용함. 그러나 위의 경우처럼, 텐서 형상의 Python 객체가 수용됨을 알 수 있음\n",
    "\n",
    "대부분의 ops는 텐서가 아닌 인수에 대해 `convert_to_tensor`를 호출함. 변환 레지스트리가 있어 NumPy의 `ndarray`, `TensorShape` Python 목록 및 `tf.Variable`과 같은 대부분의 객체 클래스는 모두 자곧으로 변환\n",
    "\n",
    "* `tf.register_tensor_conversion_function` : 자신만의 유형이 있으면, 자동으로 텐서 변환 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86f23b",
   "metadata": {},
   "source": [
    "## 비정형 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f523c01",
   "metadata": {},
   "source": [
    "비정형(ragged) : 어떤 축을 따라, 다양한 수의 요소를 가진 텐서\n",
    "\n",
    "비정형 데이터에는 `tf.ragged.RaggedTensor`를 사용\n",
    "\n",
    "##### (예) 비정형 텐서는 정규 텐서로 표현 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e09c14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "686dfb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54f9ef",
   "metadata": {},
   "source": [
    "대신, `tf.ragged.constant`를 사용하여 `tf.RaggedTensor`를 작성\n",
    "\n",
    "`tf.RaggedTensor`의 형상에는 알 수 없는 길이의 일부 축이 포함됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0367ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
     ]
    }
   ],
   "source": [
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54a649ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77db45",
   "metadata": {},
   "source": [
    "## 문자열 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd790f9a",
   "metadata": {},
   "source": [
    "`tf.string` : `dtype`이며, 텐서에서 문자열과 같은 데이터를 나타낼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0263846",
   "metadata": {},
   "source": [
    "* 문자열은 원자성이므로, Python 문자열과 같은 방식을 인덱싱 할 수 없음\n",
    "* 문자열의 길이는 텐서의 축 중 하나가 아님\n",
    "* 문자열을 조작하는 함수에 대해서는 `tf.strings`를 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e06ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 스칼라 문자열 텐서\n",
    "\n",
    "# Tensors can be strings, too here is a scalar string.\n",
    "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
    "print(scalar_string_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea74a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 문자열의 벡터\n",
    "\n",
    "# If you have three string tensors of different lengths, this is OK.\n",
    "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
    "                                 \"Quick brown fox\",\n",
    "                                 \"Lazy dog\"])\n",
    "# Note that the shape is (3,). The string length is not included.\n",
    "print(tensor_of_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cffd5b",
   "metadata": {},
   "source": [
    "`tf.string` : dtype이 뮤니코드 문자열이 아니라, 바이트 문자열임을 알 수 있음\n",
    "\n",
    "유니코드 문자을 전달하면 UTF-8로 인코딩 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3a85a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"🥳👍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8e973",
   "metadata": {},
   "source": [
    "`tf.strings.split` : 문자열이 있는 일부 기본 함수는 `tf.strings`를 포함하여 `tf.strings.split`에서 찾을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72374a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# You can use split to split a string into a set of tensors\n",
    "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "867e9202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
     ]
    }
   ],
   "source": [
    "# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,\n",
    "# as each string might be split into a different number of parts.\n",
    "print(tf.strings.split(tensor_of_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa613a71",
   "metadata": {},
   "source": [
    "`tf.string_to_number`\n",
    "\n",
    "`tf.cast` : 바이트로 변환한 다음 문자열 텐서를 숫자로 변환 가능\n",
    "\n",
    "`tf.string` : dtype은 TensorFlow 모든 원시 바이트 데이터에 사용\n",
    "\n",
    "`tf.io` : 이미지 디코딩 및 csv 구문 분석을 포함하여 데이터를 바이트로 변환하거나 바이트에서 변환하는 함수가 포함되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28dc0aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text = tf.constant(\"1 10 100\")\n",
    "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "475d58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
      "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
    "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
    "print(\"Byte strings:\", byte_strings)\n",
    "print(\"Bytes:\", byte_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85823b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unicode bytes: tf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n",
      "\n",
      "Unicode chars: tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
      "\n",
      "Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Or split it up as unicode and then decode it\n",
    "unicode_bytes = tf.constant(\"アヒル 🦆\")\n",
    "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, \"UTF-8\")\n",
    "unicode_values = tf.strings.unicode_decode(unicode_bytes, \"UTF-8\")\n",
    "\n",
    "print(\"\\nUnicode bytes:\", unicode_bytes)\n",
    "print(\"\\nUnicode chars:\", unicode_char_bytes)\n",
    "print(\"\\nUnicode values:\", unicode_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b54dee",
   "metadata": {},
   "source": [
    "## 희소 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b95cc1",
   "metadata": {},
   "source": [
    "`tf.sparse.SparseTensor` : 넓은 데이터 공간에 의미 있는 데이터가 적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc4d29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Sparse tensors store values by index in a memory-efficient manner\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# You can convert sparse tensors to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "til"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
